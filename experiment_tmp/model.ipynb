{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlApRJuPfrxq"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: deepdowmine 0.2.3\n",
      "Uninstalling deepdowmine-0.2.3:\n",
      "  Successfully uninstalled deepdowmine-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall deepdowmine -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting osqp==0.6.1\n",
      "  Using cached osqp-0.6.1.tar.gz (211 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from osqp==0.6.1) (1.26.4)\n",
      "Collecting scipy>=0.13.2 (from osqp==0.6.1)\n",
      "  Using cached scipy-1.12.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting future (from osqp==0.6.1)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Using cached scipy-1.12.0-cp312-cp312-win_amd64.whl (45.8 MB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/491.3 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 92.2/491.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 491.3/491.3 kB 4.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: osqp\n",
      "  Building wheel for osqp (setup.py): started\n",
      "  Building wheel for osqp (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for osqp\n",
      "Failed to build osqp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [311 lines of output]\n",
      "  C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\n",
      "  copying module\\interface.py -> build\\lib.win-amd64-cpython-312\\osqp\n",
      "  copying module\\utils.py -> build\\lib.win-amd64-cpython-312\\osqp\n",
      "  copying module\\__init__.py -> build\\lib.win-amd64-cpython-312\\osqp\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\codegen\n",
      "  copying module\\codegen\\code_generator.py -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\n",
      "  copying module\\codegen\\utils.py -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\n",
      "  copying module\\codegen\\__init__.py -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\basic_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\codegen_matrices_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\codegen_vectors_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\dual_infeasibility_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\feasibility_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\mkl_pardiso_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\non_convex_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\polishing_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\primal_infeasibility_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\unconstrained_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\update_matrices_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\warm_start_test.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  copying module\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\osqp\\tests\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqppurepy\n",
      "  copying modulepurepy\\interface.py -> build\\lib.win-amd64-cpython-312\\osqppurepy\n",
      "  copying modulepurepy\\_osqp.py -> build\\lib.win-amd64-cpython-312\\osqppurepy\n",
      "  copying modulepurepy\\__init__.py -> build\\lib.win-amd64-cpython-312\\osqppurepy\n",
      "  running egg_info\n",
      "  writing osqp.egg-info\\PKG-INFO\n",
      "  writing dependency_links to osqp.egg-info\\dependency_links.txt\n",
      "  writing requirements to osqp.egg-info\\requires.txt\n",
      "  writing top-level names to osqp.egg-info\\top_level.txt\n",
      "  reading manifest file 'osqp.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'osqp.egg-info\\SOURCES.txt'\n",
      "  C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\command\\build_py.py:204: _Warning: Package 'osqp.codegen.files_to_generate' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'osqp.codegen.files_to_generate' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'osqp.codegen.files_to_generate' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'osqp.codegen.files_to_generate' to be distributed and are\n",
      "          already explicitly excluding 'osqp.codegen.files_to_generate' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\command\\build_py.py:204: _Warning: Package 'osqp.codegen.sources.configure' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'osqp.codegen.sources.configure' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'osqp.codegen.sources.configure' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'osqp.codegen.sources.configure' to be distributed and are\n",
      "          already explicitly excluding 'osqp.codegen.sources.configure' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\command\\build_py.py:204: _Warning: Package 'osqp.codegen.sources.include' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'osqp.codegen.sources.include' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'osqp.codegen.sources.include' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'osqp.codegen.sources.include' to be distributed and are\n",
      "          already explicitly excluding 'osqp.codegen.sources.include' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\command\\build_py.py:204: _Warning: Package 'osqp.codegen.sources.src' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'osqp.codegen.sources.src' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'osqp.codegen.sources.src' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'osqp.codegen.sources.src' to be distributed and are\n",
      "          already explicitly excluding 'osqp.codegen.sources.src' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\codegen\\files_to_generate\n",
      "  copying module\\codegen\\files_to_generate\\CMakeLists.txt -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\files_to_generate\n",
      "  copying module\\codegen\\files_to_generate\\emosqpmodule.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\files_to_generate\n",
      "  copying module\\codegen\\files_to_generate\\example.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\files_to_generate\n",
      "  copying module\\codegen\\files_to_generate\\setup.py -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\files_to_generate\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\configure\n",
      "  copying module\\codegen\\sources\\configure\\osqp_configure.h.in -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\configure\n",
      "  copying module\\codegen\\sources\\configure\\qdldl_types.h.in -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\configure\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\CMakeLists.txt -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\auxil.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\constants.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\error.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\glob_opts.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\kkt.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\lin_alg.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\osqp.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\proj.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\qdldl.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\qdldl_interface.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\scaling.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\types.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  copying module\\codegen\\sources\\include\\util.h -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\include\n",
      "  creating build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\CMakeLists.txt -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\auxil.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\error.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\kkt.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\lin_alg.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\osqp.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\proj.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\qdldl.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\qdldl_interface.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\scaling.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  copying module\\codegen\\sources\\src\\util.c -> build\\lib.win-amd64-cpython-312\\osqp\\codegen\\sources\\src\n",
      "  running build_ext\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-install-dz7o9ku4\\osqp_d3f50fc596594395bd2bdb6e3933a86e\\setup.py\", line 164, in build_extensions\n",
      "      check_output(['cmake', '--version'])\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 466, in check_output\n",
      "      return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 548, in run\n",
      "      with Popen(*popenargs, **kwargs) as process:\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "      hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-install-dz7o9ku4\\osqp_d3f50fc596594395bd2bdb6e3933a86e\\setup.py\", line 208, in <module>\n",
      "      setup(name='osqp',\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 364, in run\n",
      "      self.run_command(\"build\")\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 88, in run\n",
      "      _build_ext.run(self)\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 345, in run\n",
      "      self.build_extensions()\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-install-dz7o9ku4\\osqp_d3f50fc596594395bd2bdb6e3933a86e\\setup.py\", line 166, in build_extensions\n",
      "      raise RuntimeError(\"CMake must be installed to build OSQP\")\n",
      "  RuntimeError: CMake must be installed to build OSQP\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for osqp\n",
      "ERROR: Could not build wheels for osqp, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install osqp==0.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvaaDKBoMaO8",
    "outputId": "11c8de58-a8b7-4df1-ffd1-22e6b823df02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/dsman1823/deepdowmine.git\n",
      "  Cloning https://github.com/dsman1823/deepdowmine.git to c:\\users\\r0913246\\appdata\\local\\temp\\pip-req-build-gg4ff6qz\n",
      "  Resolved https://github.com/dsman1823/deepdowmine.git to commit 41051a7f693cc28dc1a8c3d10e6af02b4cc87d2b\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cvxpylayers (from deepdowmine==0.2.3)\n",
      "  Using cached cvxpylayers-0.1.6-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting matplotlib (from deepdowmine==0.2.3)\n",
      "  Using cached matplotlib-3.8.3-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting mlflow (from deepdowmine==0.2.3)\n",
      "  Using cached mlflow-2.11.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting numpy>=1.16.5 (from deepdowmine==0.2.3)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pandas (from deepdowmine==0.2.3)\n",
      "  Using cached pandas-2.2.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow (from deepdowmine==0.2.3)\n",
      "  Using cached pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting seaborn (from deepdowmine==0.2.3)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting torch>=1.5 (from deepdowmine==0.2.3)\n",
      "  Using cached torch-2.2.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting tensorboard (from deepdowmine==0.2.3)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tqdm (from deepdowmine==0.2.3)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting filelock (from torch>=1.5->deepdowmine==0.2.3)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from torch>=1.5->deepdowmine==0.2.3) (4.9.0)\n",
      "Collecting sympy (from torch>=1.5->deepdowmine==0.2.3)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.5->deepdowmine==0.2.3)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from torch>=1.5->deepdowmine==0.2.3) (3.1.3)\n",
      "Collecting fsspec (from torch>=1.5->deepdowmine==0.2.3)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting scipy>=1.1.0 (from cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached scipy-1.12.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting diffcp>=1.0.13 (from cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached diffcp-1.0.23.tar.gz (2.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting cvxpy>=1.1.0a4 (from cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached cvxpy-1.4.2.tar.gz (1.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->deepdowmine==0.2.3)\n",
      "  Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->deepdowmine==0.2.3)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->deepdowmine==0.2.3)\n",
      "  Using cached fonttools-4.50.0-cp312-cp312-win_amd64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->deepdowmine==0.2.3)\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from matplotlib->deepdowmine==0.2.3) (23.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->deepdowmine==0.2.3)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from matplotlib->deepdowmine==0.2.3) (2.8.2)\n",
      "Collecting click<9,>=7.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle<4 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting entrypoints<1 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from mlflow->deepdowmine==0.2.3) (6.0.1)\n",
      "Collecting protobuf<5,>=3.12.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pytz<2025 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from mlflow->deepdowmine==0.2.3) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from mlflow->deepdowmine==0.2.3) (2.31.0)\n",
      "Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting Flask<4 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached flask-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting querystring-parser<2 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached SQLAlchemy-2.0.29-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting scikit-learn<2 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting pyarrow<16,>=4.0.0 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached pyarrow-15.0.2-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting graphene<4 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting waitress<4 (from mlflow->deepdowmine==0.2.3)\n",
      "  Using cached waitress-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->deepdowmine==0.2.3)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->deepdowmine==0.2.3)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->deepdowmine==0.2.3)\n",
      "  Using cached grpcio-1.62.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from tensorboard->deepdowmine==0.2.3) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from tensorboard->deepdowmine==0.2.3) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->deepdowmine==0.2.3)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->deepdowmine==0.2.3)\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from tqdm->deepdowmine==0.2.3) (0.4.6)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached Mako-1.3.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting osqp>=0.6.2 (from cvxpy>=1.1.0a4->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached osqp-0.6.5-cp312-cp312-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting ecos>=2 (from cvxpy>=1.1.0a4->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached ecos-2.0.13-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting clarabel>=0.5.0 (from cvxpy>=1.1.0a4->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached clarabel-0.7.1-cp37-abi3-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting scs>=3.0 (from cvxpy>=1.1.0a4->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached scs-3.2.4.post1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting pybind11 (from cvxpy>=1.1.0a4->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting threadpoolctl>=1.1 (from diffcp>=1.0.13->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from docker<8,>=4.0.0->mlflow->deepdowmine==0.2.3) (2.1.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from docker<8,>=4.0.0->mlflow->deepdowmine==0.2.3) (305.1)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<4->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<4->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from jinja2->torch>=1.5->deepdowmine==0.2.3) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from requests<3,>=2.17.3->mlflow->deepdowmine==0.2.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from requests<3,>=2.17.3->mlflow->deepdowmine==0.2.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\anaconda3\\envs\\ddow\\lib\\site-packages (from requests<3,>=2.17.3->mlflow->deepdowmine==0.2.3) (2024.2.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn<2->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3,>=1.4.0->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.5->deepdowmine==0.2.3)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow->deepdowmine==0.2.3)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting scipy>=1.1.0 (from cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached scipy-1.11.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting qdldl (from osqp>=0.6.2->cvxpy>=1.1.0a4->cvxpylayers->deepdowmine==0.2.3)\n",
      "  Using cached qdldl-0.1.7.post0.tar.gz (70 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached torch-2.2.1-cp312-cp312-win_amd64.whl (198.5 MB)\n",
      "Using cached cvxpylayers-0.1.6-py3-none-any.whl (31 kB)\n",
      "Using cached matplotlib-3.8.3-cp312-cp312-win_amd64.whl (7.6 MB)\n",
      "Using cached pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached mlflow-2.11.3-py3-none-any.whl (19.7 MB)\n",
      "Using cached pandas-2.2.1-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl (187 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached flask-3.0.2-py3-none-any.whl (101 kB)\n",
      "Using cached fonttools-4.50.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Using cached graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "Using cached grpcio-1.62.1-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "Using cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached pyarrow-15.0.2-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Using cached scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
      "Using cached SQLAlchemy-2.0.29-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached waitress-3.0.0-py3-none-any.whl (56 kB)\n",
      "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached clarabel-0.7.1-cp37-abi3-win_amd64.whl (321 kB)\n",
      "Using cached ecos-2.0.13-cp312-cp312-win_amd64.whl (72 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached osqp-0.6.5-cp312-cp312-win_amd64.whl (293 kB)\n",
      "Using cached scipy-1.11.4-cp312-cp312-win_amd64.whl (43.7 MB)\n",
      "Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Using cached scs-3.2.4.post1-cp312-cp312-win_amd64.whl (8.4 MB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Using cached Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: deepdowmine, cvxpy, diffcp, qdldl\n",
      "  Building wheel for deepdowmine (setup.py): started\n",
      "  Building wheel for deepdowmine (setup.py): finished with status 'done'\n",
      "  Created wheel for deepdowmine: filename=deepdowmine-0.2.3-py3-none-any.whl size=58134 sha256=6478945d66e9dccef255e2fb25f6101cd1d2170e9c10be9eb4642cdef344e917\n",
      "  Stored in directory: C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-l8v9zv6r\\wheels\\58\\28\\b6\\e0ff682232450129163c1a07c2bf53bc18437669e9eefc1d20\n",
      "  Building wheel for cvxpy (pyproject.toml): started\n",
      "  Building wheel for cvxpy (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for diffcp (pyproject.toml): started\n",
      "  Building wheel for diffcp (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for qdldl (pyproject.toml): started\n",
      "  Building wheel for qdldl (pyproject.toml): finished with status 'error'\n",
      "Successfully built deepdowmine\n",
      "Failed to build cvxpy diffcp qdldl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/dsman1823/deepdowmine.git 'C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-req-build-gg4ff6qz'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for cvxpy (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [438 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\n",
      "  copying cvxpy\\error.py -> build\\lib.win-amd64-cpython-312\\cvxpy\n",
      "  copying cvxpy\\settings.py -> build\\lib.win-amd64-cpython-312\\cvxpy\n",
      "  copying cvxpy\\version.py -> build\\lib.win-amd64-cpython-312\\cvxpy\n",
      "  copying cvxpy\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\n",
      "  creating build\\lib.win-amd64-cpython-312\\setup\n",
      "  copying setup\\extensions.py -> build\\lib.win-amd64-cpython-312\\setup\n",
      "  copying setup\\versioning.py -> build\\lib.win-amd64-cpython-312\\setup\n",
      "  copying setup\\__init__.py -> build\\lib.win-amd64-cpython-312\\setup\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\atom.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\axis_atom.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\condition_number.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\cummax.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\dist_ratio.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\dotsort.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\errormsg.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\eye_minus_inv.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\gen_lambda_max.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\geo_mean.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\gmatmul.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\harmonic_mean.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\inv_prod.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\lambda_max.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\lambda_min.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\lambda_sum_largest.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\lambda_sum_smallest.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\length.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\log_det.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\log_sum_exp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\matrix_frac.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\max.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\min.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\mixed_norm.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\norm.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\norm1.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\norm_inf.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\norm_nuc.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\one_minus_pos.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\perspective.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\pf_eigenvalue.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\pnorm.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\prod.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\ptp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\quad_form.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\quad_over_lin.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\sigma_max.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\sign.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\stats.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\sum_largest.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\sum_smallest.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\sum_squares.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\suppfunc.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\total_variation.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\tr_inv.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\von_neumann_entr.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  copying cvxpy\\atoms\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\cones.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\constraint.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\exponential.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\finite_set.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\nonpos.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\power.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\psd.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\second_order.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\utilities.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\zero.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  copying cvxpy\\constraints\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\constraints\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\cvxcore\n",
      "  copying cvxpy\\cvxcore\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\cvxcore\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\n",
      "  copying cvxpy\\expressions\\cvxtypes.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\n",
      "  copying cvxpy\\expressions\\expression.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\n",
      "  copying cvxpy\\expressions\\leaf.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\n",
      "  copying cvxpy\\expressions\\variable.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\n",
      "  copying cvxpy\\expressions\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\interface\n",
      "  copying cvxpy\\interface\\base_matrix_interface.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\n",
      "  copying cvxpy\\interface\\matrix_utilities.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\n",
      "  copying cvxpy\\interface\\scipy_wrapper.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\n",
      "  copying cvxpy\\interface\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  copying cvxpy\\lin_ops\\canon_backend.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  copying cvxpy\\lin_ops\\lin_constraints.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  copying cvxpy\\lin_ops\\lin_op.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  copying cvxpy\\lin_ops\\lin_utils.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  copying cvxpy\\lin_ops\\tree_mat.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  copying cvxpy\\lin_ops\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\lin_ops\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  copying cvxpy\\problems\\iterative.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  copying cvxpy\\problems\\objective.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  copying cvxpy\\problems\\param_prob.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  copying cvxpy\\problems\\problem.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  copying cvxpy\\problems\\xpress_problem.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  copying cvxpy\\problems\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\problems\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\canonicalization.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\chain.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\cvx_attr2constr.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\eval_params.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\flip_objective.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\inverse_data.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\matrix_stuffing.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\reduction.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\solution.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\utilities.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  copying cvxpy\\reductions\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\base_test.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\ram_limited.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\solver_test_helpers.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_atoms.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_benchmarks.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_complex.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_cone2cone.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_conic_solvers.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_constant.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_constant_atoms.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_constraints.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_convolution.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_copy.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_curvature.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_custom_solver.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_derivative.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_dgp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_dgp2dcp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_domain.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_dpp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_dqcp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_errors.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_examples.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_expressions.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_expression_methods.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_grad.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_gurobi_write.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_interfaces.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_KKT.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_kron_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_linalg_utils.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_linear_cone.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_lin_ops.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_matrices.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_mip_vars.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_monotonicity.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_nonlinear_atoms.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_objectives.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_param_cone_prog.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_param_quad_prog.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_perspective.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_power_tools.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_problem.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_python_backends.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_qp_solvers.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_quadratic.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_quad_form.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_scalarize.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_semidefinite_vars.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_shape.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_sign.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_suppfunc.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_valinvec2mixedint.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_versioning.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\test_von_neumann_entr.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  copying cvxpy\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\tests\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  copying cvxpy\\transforms\\indicator.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  copying cvxpy\\transforms\\linearize.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  copying cvxpy\\transforms\\partial_optimize.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  copying cvxpy\\transforms\\scalarize.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  copying cvxpy\\transforms\\suppfunc.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  copying cvxpy\\transforms\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\transforms\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\canonical.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\coeff_extractor.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\cvxpy_upgrade.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\debug_tools.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\deterministic.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\grad.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\key_utils.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\linalg.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\performance_utils.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\perspective_utils.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\power_tools.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\replace_quad_forms.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\scopes.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\shape.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\sign.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\versioning.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  copying cvxpy\\utilities\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\add_expr.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\affine_atom.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\binary_operators.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\bmat.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\conj.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\conv.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\cumsum.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\diag.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\diff.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\hstack.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\imag.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\index.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\kron.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\partial_trace.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\partial_transpose.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\promote.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\real.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\reshape.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\sum.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\trace.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\transpose.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\unary_operators.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\upper_tri.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\vec.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\vstack.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\wraps.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  copying cvxpy\\atoms\\affine\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\affine\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\abs.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\ceil.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\elementwise.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\entr.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\exp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\huber.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\inv_pos.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\kl_div.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\log.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\log1p.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\loggamma.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\logistic.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\log_normcdf.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\maximum.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\minimum.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\neg.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\pos.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\power.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\rel_entr.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\scalene.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\sqrt.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\square.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\xexp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  copying cvxpy\\atoms\\elementwise\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\atoms\\elementwise\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\cvxcore\\python\n",
      "  copying cvxpy\\cvxcore\\python\\canonInterface.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\cvxcore\\python\n",
      "  copying cvxpy\\cvxcore\\python\\cvxcore.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\cvxcore\\python\n",
      "  copying cvxpy\\cvxcore\\python\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\cvxcore\\python\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\\constants\n",
      "  copying cvxpy\\expressions\\constants\\callback_param.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\\constants\n",
      "  copying cvxpy\\expressions\\constants\\constant.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\\constants\n",
      "  copying cvxpy\\expressions\\constants\\parameter.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\\constants\n",
      "  copying cvxpy\\expressions\\constants\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\expressions\\constants\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\interface\\numpy_interface\n",
      "  copying cvxpy\\interface\\numpy_interface\\matrix_interface.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\\numpy_interface\n",
      "  copying cvxpy\\interface\\numpy_interface\\ndarray_interface.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\\numpy_interface\n",
      "  copying cvxpy\\interface\\numpy_interface\\sparse_matrix_interface.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\\numpy_interface\n",
      "  copying cvxpy\\interface\\numpy_interface\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\interface\\numpy_interface\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\n",
      "  copying cvxpy\\reductions\\complex2real\\complex2real.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\n",
      "  copying cvxpy\\reductions\\complex2real\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\cone2cone\n",
      "  copying cvxpy\\reductions\\cone2cone\\affine2direct.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\cone2cone\n",
      "  copying cvxpy\\reductions\\cone2cone\\approximations.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\cone2cone\n",
      "  copying cvxpy\\reductions\\cone2cone\\exotic2common.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\cone2cone\n",
      "  copying cvxpy\\reductions\\cone2cone\\soc2psd.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\cone2cone\n",
      "  copying cvxpy\\reductions\\cone2cone\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\cone2cone\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\n",
      "  copying cvxpy\\reductions\\dcp2cone\\cone_matrix_stuffing.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\n",
      "  copying cvxpy\\reductions\\dcp2cone\\dcp2cone.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\n",
      "  copying cvxpy\\reductions\\dcp2cone\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\dgp2dcp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\util.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\discrete2mixedint\n",
      "  copying cvxpy\\reductions\\discrete2mixedint\\valinvec2mixedint.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\discrete2mixedint\n",
      "  copying cvxpy\\reductions\\discrete2mixedint\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\discrete2mixedint\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dqcp2dcp\n",
      "  copying cvxpy\\reductions\\dqcp2dcp\\dqcp2dcp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dqcp2dcp\n",
      "  copying cvxpy\\reductions\\dqcp2dcp\\inverse.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dqcp2dcp\n",
      "  copying cvxpy\\reductions\\dqcp2dcp\\sets.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dqcp2dcp\n",
      "  copying cvxpy\\reductions\\dqcp2dcp\\tighten.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dqcp2dcp\n",
      "  copying cvxpy\\reductions\\dqcp2dcp\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dqcp2dcp\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\eliminate_pwl.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\qp2symbolic_qp.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\qp_matrix_stuffing.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\bisection.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\compr_matrix.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\constant_solver.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\defines.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\intermediate_chain.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\kktsolver.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\solver.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\solving_chain.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\utilities.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  copying cvxpy\\reductions\\solvers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\abs_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\aff_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\constant_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\equality_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\inequality_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\matrix_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\param_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\pnorm_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\psd_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\soc_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\variable_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  copying cvxpy\\reductions\\complex2real\\canonicalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\complex2real\\canonicalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\entr_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\exp_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\geo_mean_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\huber_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\indicator_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\kl_div_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\lambda_max_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\lambda_sum_largest_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\log1p_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\logistic_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\log_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\log_det_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\log_sum_exp_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\matrix_frac_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\mul_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\normNuc_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\perspective_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\pnorm_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\power_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\quad_form_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\quad_over_lin_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\rel_entr_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\sigma_max_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\suppfunc_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\tr_inv_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\von_neumann_entr_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\xexp_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dcp2cone\\canonicalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dcp2cone\\canonicalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\add_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\constant_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\div_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\exp_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\eye_minus_inv_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\finite_set_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\geo_mean_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\gmatmul_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\log_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\mulexpression_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\mul_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\nonpos_constr_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\norm1_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\norm_inf_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\one_minus_pos_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\parameter_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\pf_eigenvalue_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\pnorm_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\power_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\prod_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\quad_form_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\quad_over_lin_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\sum_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\trace_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\xexp_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\zero_constr_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  copying cvxpy\\reductions\\dgp2dcp\\canonicalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\dgp2dcp\\canonicalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\abs_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\cummax_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\cumsum_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\dotsort_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\maximum_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\max_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\minimum_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\min_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\norm1_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\norm_inf_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\sum_largest_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  copying cvxpy\\reductions\\eliminate_pwl\\canonicalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\eliminate_pwl\\canonicalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\\canonicalizers\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\canonicalizers\\huber_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\\canonicalizers\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\canonicalizers\\power_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\\canonicalizers\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\canonicalizers\\quad_form_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\\canonicalizers\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\canonicalizers\\quad_over_lin_canon.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\\canonicalizers\n",
      "  copying cvxpy\\reductions\\qp2quad_form\\canonicalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\qp2quad_form\\canonicalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\cbc_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\clarabel_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\conic_solver.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\copt_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\cplex_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\cvxopt_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\diffcp_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\ecos_bb_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\ecos_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\glop_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\glpk_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\glpk_mi_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\gurobi_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\mosek_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\nag_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\pdlp_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\scipy_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\scip_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\scs_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\sdpa_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\xpress_conif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\conic_solvers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\conic_solvers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\lp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\lp_solvers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\lp_solvers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\copt_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\cplex_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\gurobi_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\osqp_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\piqp_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\proxqp_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\qp_solver.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\xpress_qpif.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  copying cvxpy\\reductions\\solvers\\qp_solvers\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\reductions\\solvers\\qp_solvers\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\\cpp\n",
      "  copying cvxpy\\utilities\\cpp\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\\cpp\n",
      "  creating build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\\cpp\\sparsecholesky\n",
      "  copying cvxpy\\utilities\\cpp\\sparsecholesky\\__init__.py -> build\\lib.win-amd64-cpython-312\\cvxpy\\utilities\\cpp\\sparsecholesky\n",
      "  copying cvxpy\\py.typed -> build\\lib.win-amd64-cpython-312\\cvxpy\n",
      "  running build_ext\n",
      "  building '_cvxcore' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cvxpy\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for diffcp (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [18 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\diffcp\n",
      "  copying diffcp\\cones.py -> build\\lib.win-amd64-cpython-312\\diffcp\n",
      "  copying diffcp\\cone_program.py -> build\\lib.win-amd64-cpython-312\\diffcp\n",
      "  copying diffcp\\utils.py -> build\\lib.win-amd64-cpython-312\\diffcp\n",
      "  copying diffcp\\__init__.py -> build\\lib.win-amd64-cpython-312\\diffcp\n",
      "  creating build\\lib.win-amd64-cpython-312\\tests\n",
      "  copying tests\\test_cone_prog_diff.py -> build\\lib.win-amd64-cpython-312\\tests\n",
      "  copying tests\\test_ecos.py -> build\\lib.win-amd64-cpython-312\\tests\n",
      "  copying tests\\test_scs.py -> build\\lib.win-amd64-cpython-312\\tests\n",
      "  copying tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\tests\n",
      "  running build_ext\n",
      "  building '_diffcp' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for diffcp\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for qdldl (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [73 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 81, in build_extensions\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 466, in check_output\n",
      "      return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 548, in run\n",
      "      with Popen(*popenargs, **kwargs) as process:\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "      hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Anaconda3\\envs\\ddow\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 251, in build_wheel\n",
      "      return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 410, in build_wheel\n",
      "      return self._build_with_temp_dir(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 395, in _build_with_temp_dir\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 113, in <module>\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 104, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 967, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\normal\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 368, in run\n",
      "      self.run_command(\"build\")\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 967, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 967, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 91, in run\n",
      "      _build_ext.run(self)\n",
      "    File \"C:\\Users\\r0913246\\AppData\\Local\\Temp\\pip-build-env-691q74zo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 345, in run\n",
      "      self.build_extensions()\n",
      "    File \"<string>\", line 83, in build_extensions\n",
      "  RuntimeError: CMake must be installed to build qdldl\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for qdldl\n",
      "ERROR: Could not build wheels for cvxpy, diffcp, qdldl, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/dsman1823/deepdowmine.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tfN21pcMhatf"
   },
   "outputs": [],
   "source": [
    "from deepdowmine.layers import CovarianceMatrix\n",
    "from deepdowmine.layers.allocate import NumericalMarkowitzWithShorting\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eWwxa1MBf-Sk"
   },
   "outputs": [],
   "source": [
    "from deepdowmine.benchmarks import Benchmark, OneOverN, Random\n",
    "from deepdowmine.callbacks import EarlyStoppingCallback\n",
    "from deepdowmine.data import InRAMDataset, RigidDataLoader, prepare_standard_scaler, Scale, SeqRigidDataLoader, WeeklyRigidDataLoader\n",
    "from deepdowmine.data.synthetic import sin_single\n",
    "from deepdowmine.experiments import Run\n",
    "from deepdowmine.layers import SoftmaxAllocator\n",
    "from deepdowmine.losses import MeanReturns, SharpeRatio, MaximumDrawdown, StandardDeviation\n",
    "from deepdowmine.visualize import generate_metrics_table, generate_weights_table, plot_metrics, plot_weight_heatmap\n",
    "from deepdowmine.nn import BachelierNetWithShorting, BachelierNet, KeynesNet, BachelierNetWithShortingUpd, LinearNetMine\n",
    "from deepdowmine.nn import RnnNetFullOpti, LstmNetFullOpti, DenseNetMinVar, DenseNetFullOpti, ConvNetFullOpti\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNqxm-tdcv3Y"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x-bSnRLxonV_"
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "returns = pd.read_csv('train_data_0.csv', index_col = 0).to_numpy()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr7u61ueYxcB",
    "outputId": "e1e9183a-1971-46b5-ab77-f79f8ba6bb65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3511"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5G-3j5QtgEH6"
   },
   "outputs": [],
   "source": [
    "n_timesteps, n_assets = len(returns), 5#11**4, 450\n",
    "\n",
    "#returns = np.random.normal(0, .2, size = (n_timesteps, n_assets))\n",
    "\n",
    "lookback, gap, horizon = 50, 0, 5# 40, 0, 5   loss=-0.09645, test_loss=-0.08003]\n",
    "n_samples = n_timesteps - lookback - horizon - gap + 1\n",
    "\n",
    "indices = np.arange(n_samples)\n",
    "# np.random.seed(32)\n",
    "# np.random.shuffle(indices)\n",
    "split_ix = int(n_samples * 0.8)\n",
    "indices_train = list(range(split_ix))\n",
    "indices_test = list(range(split_ix + lookback + horizon, n_samples))\n",
    "\n",
    "# Split the indices array into training and test sets\n",
    "split_ix = int(n_samples * 0.9)\n",
    "indices_train = indices[:split_ix]\n",
    "indices_test = indices[split_ix:]\n",
    "\n",
    "\n",
    "# print('Train range: {}:{}\\nTest range: {}:{}'.format(indices_train[0], indices_train[-1],\n",
    "#                                                      indices_test[0], indices_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3WWSpDn2IuhS"
   },
   "outputs": [],
   "source": [
    "def transform_returns_to_Xy_tensors(returns, lookback, n_timesteps, horizon, gap):\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for i in range(lookback, n_timesteps - horizon - gap + 1):\n",
    "        X_list.append(returns[i - lookback: i, :])\n",
    "        y_list.append(returns[i + gap: i + gap + horizon, :])\n",
    "\n",
    "    X = np.stack(X_list, axis=0)[:, None, ...]\n",
    "    y = np.stack(y_list, axis=0)[:, None, ...]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lw1e3TQXgHI5"
   },
   "outputs": [],
   "source": [
    "\n",
    "#returns = np.random.normal(0, .2, size = (n_timesteps, n_assets))\n",
    "\n",
    "# X_list, y_list = [], []\n",
    "\n",
    "# for i in range(lookback, n_timesteps - horizon - gap + 1):\n",
    "#     X_list.append(returns[i - lookback: i, :])\n",
    "#     y_list.append(returns[i + gap: i + gap + horizon, :])\n",
    "\n",
    "# X = np.stack(X_list, axis=0)[:, None, ...]\n",
    "# y = np.stack(y_list, axis=0)[:, None, ...]\n",
    "X, y = transform_returns_to_Xy_tensors(returns, lookback, n_timesteps, horizon, gap)\n",
    "#print('X: {}, y: {}'.format(X.shape, y.shape))\n",
    "\n",
    "# means, stds = prepare_standard_scaler(X, indices=indices_train)\n",
    "# print('mean: {}, std: {}'.format(means, stds))\n",
    "\n",
    "dataset = InRAMDataset(X, y)\n",
    "#, transform=Scale(means, stds))\n",
    "dataloader_train = SeqRigidDataLoader(dataset,\n",
    "                                   indices=indices_train,\n",
    "                                   batch_size=32)\n",
    "\n",
    "dataloader_test = SeqRigidDataLoader(dataset,\n",
    "                                  indices=indices_test,\n",
    "                                  batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka29tJgfco0Z"
   },
   "source": [
    "# Network setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8DwRhcJKfRU-"
   },
   "outputs": [],
   "source": [
    "from deepdowmine.losses import SharpeRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ejAd0srJV0xX"
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from deepdowmine.layers.misc import Cov2Corr, CovarianceMatrix, KMeans\n",
    "# from deepdowmine.layers.transform import Cov\n",
    "import deepdowmine.layers.transform as ddt\n",
    "\n",
    "from deepdowmine.nn import UpdNumericalMarkowitzWithShorting, MinVarWithShorting, BachelierNetWithShortingUpd, DenseNetMinVar\n",
    "from deepdowmine.layers import RNN, AttentionCollapse, AverageCollapse\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "278apII78IIU"
   },
   "outputs": [],
   "source": [
    "n_samples, n_input_channels, lookback, n_assets = 32, 1, 50, 5\n",
    "n_output_channels = 8\n",
    "x = torch.rand(n_samples, n_input_channels, lookback, n_assets)\n",
    "layer = nn.RNN(5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OoEzSLRz-pc9"
   },
   "outputs": [],
   "source": [
    "#tmp['conv_res'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nDWQuzbCWRqA"
   },
   "outputs": [],
   "source": [
    "from deepdowmine.nn import RnnNetMinVar, LstmNetMinVar, ConvNetMinVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOuNfpMXgcKN",
    "outputId": "c116905c-4f66-43bc-e8e2-fd7c37945835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNetFullOpti(\n",
      "  (norm_layer): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear_for_cov): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (covariance_layer): CovarianceMatrix()\n",
      "  (linear): Linear(in_features=250, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (portfolio_opt_layer): UpdNumericalMarkowitzWithShorting(\n",
      "    (cvxpylayer): CvxpyLayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = DenseNetFullOpti(1, 50, 5, .2)\n",
    "print(network)\n",
    "network = network.train()\n",
    "loss = SharpeRatio()\n",
    "run = Run(network,\n",
    "          loss,\n",
    "          dataloader_train,\n",
    "          val_dataloaders={\n",
    "              'test': dataloader_test,\n",
    "              'train': dataloader_train\n",
    "              },\n",
    "          optimizer=torch.optim.Adam(network.parameters(), amsgrad=True),\n",
    "          callbacks=[EarlyStoppingCallback(metric_name='loss',\n",
    "                                           dataloader_name='test',\n",
    "                                           patience=5)]) #15 # patience controlls amount offffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffrfvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL_SktboD7l8"
   },
   "source": [
    "# Train start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wo4B68DGhMjY",
    "outputId": "83c2c8a2-3768-4416-8c7b-d1c62725dc21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:   0%|                                                                               | 0/98 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:   1%|▋                                                                      | 1/98 [00:00<00:21,  4.53it/s]\u001b[A\n",
      "Epoch 0:   1%|▌                                                       | 1/98 [00:00<00:21,  4.53it/s, loss=-0.00470]\u001b[A\n",
      "Epoch 0:   2%|█▏                                                      | 2/98 [00:00<00:20,  4.64it/s, loss=-0.00470]\u001b[A\n",
      "Epoch 0:   2%|█▏                                                       | 2/98 [00:00<00:20,  4.64it/s, loss=0.02757]\u001b[A\n",
      "Epoch 0:   3%|█▋                                                       | 3/98 [00:00<00:19,  4.76it/s, loss=0.02757]\u001b[A\n",
      "Epoch 0:   3%|█▋                                                       | 3/98 [00:00<00:19,  4.76it/s, loss=0.03118]\u001b[A\n",
      "Epoch 0:   4%|██▎                                                      | 4/98 [00:00<00:20,  4.56it/s, loss=0.03118]\u001b[A\n",
      "Epoch 0:   4%|██▎                                                     | 4/98 [00:00<00:20,  4.56it/s, loss=-0.02208]\u001b[A\n",
      "Epoch 0:   5%|██▊                                                     | 5/98 [00:01<00:22,  4.21it/s, loss=-0.02208]\u001b[A\n",
      "Epoch 0:   5%|██▊                                                     | 5/98 [00:01<00:22,  4.21it/s, loss=-0.04379]\u001b[A\n",
      "Epoch 0:   6%|███▍                                                    | 6/98 [00:01<00:22,  4.11it/s, loss=-0.04379]\u001b[A\n",
      "Epoch 0:   6%|███▍                                                    | 6/98 [00:01<00:22,  4.11it/s, loss=-0.03484]\u001b[A\n",
      "Epoch 0:   7%|████                                                    | 7/98 [00:01<00:21,  4.15it/s, loss=-0.03484]\u001b[A\n",
      "Epoch 0:   7%|████                                                    | 7/98 [00:01<00:21,  4.15it/s, loss=-0.02498]\u001b[A\n",
      "Epoch 0:   8%|████▌                                                   | 8/98 [00:01<00:22,  4.01it/s, loss=-0.02498]\u001b[A\n",
      "Epoch 0:   8%|████▌                                                   | 8/98 [00:01<00:22,  4.01it/s, loss=-0.03117]\u001b[A\n",
      "Epoch 0:   9%|█████▏                                                  | 9/98 [00:02<00:22,  4.00it/s, loss=-0.03117]\u001b[A\n",
      "Epoch 0:   9%|█████▏                                                  | 9/98 [00:02<00:22,  4.00it/s, loss=-0.05283]\u001b[A\n",
      "Epoch 0:  10%|█████▌                                                 | 10/98 [00:02<00:21,  4.15it/s, loss=-0.05283]\u001b[A\n",
      "Epoch 0:  10%|█████▌                                                 | 10/98 [00:02<00:21,  4.15it/s, loss=-0.03355]\u001b[A\n",
      "Epoch 0:  11%|██████▏                                                | 11/98 [00:02<00:20,  4.19it/s, loss=-0.03355]\u001b[A\n",
      "Epoch 0:  11%|██████▏                                                | 11/98 [00:02<00:20,  4.19it/s, loss=-0.02251]\u001b[A\n",
      "Epoch 0:  12%|██████▋                                                | 12/98 [00:02<00:19,  4.33it/s, loss=-0.02251]\u001b[A\n",
      "Epoch 0:  12%|██████▋                                                | 12/98 [00:02<00:19,  4.33it/s, loss=-0.00054]\u001b[A\n",
      "Epoch 0:  13%|███████▎                                               | 13/98 [00:03<00:19,  4.37it/s, loss=-0.00054]\u001b[A\n",
      "Epoch 0:  13%|███████▍                                                | 13/98 [00:03<00:19,  4.37it/s, loss=0.01612]\u001b[A\n",
      "Epoch 0:  14%|████████                                                | 14/98 [00:03<00:19,  4.35it/s, loss=0.01612]\u001b[A\n",
      "Epoch 0:  14%|████████                                                | 14/98 [00:03<00:19,  4.35it/s, loss=0.01436]\u001b[A\n",
      "Epoch 0:  15%|████████▌                                               | 15/98 [00:03<00:18,  4.38it/s, loss=0.01436]\u001b[A\n",
      "Epoch 0:  15%|████████▌                                               | 15/98 [00:03<00:18,  4.38it/s, loss=0.01956]\u001b[A\n",
      "Epoch 0:  16%|█████████▏                                              | 16/98 [00:03<00:18,  4.39it/s, loss=0.01956]\u001b[A\n",
      "Epoch 0:  16%|█████████▏                                              | 16/98 [00:03<00:18,  4.39it/s, loss=0.02162]\u001b[A\n",
      "Epoch 0:  17%|█████████▋                                              | 17/98 [00:03<00:18,  4.44it/s, loss=0.02162]\u001b[A\n",
      "Epoch 0:  17%|█████████▋                                              | 17/98 [00:03<00:18,  4.44it/s, loss=0.01437]\u001b[A\n",
      "Epoch 0:  18%|██████████▎                                             | 18/98 [00:04<00:17,  4.49it/s, loss=0.01437]\u001b[A\n",
      "Epoch 0:  18%|██████████▎                                             | 18/98 [00:04<00:17,  4.49it/s, loss=0.00257]\u001b[A\n",
      "Epoch 0:  19%|██████████▊                                             | 19/98 [00:04<00:17,  4.43it/s, loss=0.00257]\u001b[A\n",
      "Epoch 0:  19%|██████████▋                                            | 19/98 [00:04<00:17,  4.43it/s, loss=-0.00890]\u001b[A\n",
      "Epoch 0:  20%|███████████▏                                           | 20/98 [00:04<00:17,  4.44it/s, loss=-0.00890]\u001b[A\n",
      "Epoch 0:  20%|███████████▏                                           | 20/98 [00:04<00:17,  4.44it/s, loss=-0.02535]\u001b[A\n",
      "Epoch 0:  21%|███████████▊                                           | 21/98 [00:04<00:17,  4.51it/s, loss=-0.02535]\u001b[A\n",
      "Epoch 0:  21%|███████████▊                                           | 21/98 [00:04<00:17,  4.51it/s, loss=-0.03145]\u001b[A\n",
      "Epoch 0:  22%|████████████▎                                          | 22/98 [00:05<00:17,  4.39it/s, loss=-0.03145]\u001b[A\n",
      "Epoch 0:  22%|████████████▎                                          | 22/98 [00:05<00:17,  4.39it/s, loss=-0.02302]\u001b[A\n",
      "Epoch 0:  23%|████████████▉                                          | 23/98 [00:05<00:18,  4.14it/s, loss=-0.02302]\u001b[A\n",
      "Epoch 0:  23%|████████████▉                                          | 23/98 [00:05<00:18,  4.14it/s, loss=-0.01760]\u001b[A\n",
      "Epoch 0:  24%|█████████████▍                                         | 24/98 [00:05<00:17,  4.21it/s, loss=-0.01760]\u001b[A\n",
      "Epoch 0:  24%|█████████████▍                                         | 24/98 [00:05<00:17,  4.21it/s, loss=-0.02365]\u001b[A\n",
      "Epoch 0:  26%|██████████████                                         | 25/98 [00:05<00:17,  4.20it/s, loss=-0.02365]\u001b[A\n",
      "Epoch 0:  26%|██████████████                                         | 25/98 [00:05<00:17,  4.20it/s, loss=-0.01381]\u001b[A\n",
      "Epoch 0:  27%|██████████████▌                                        | 26/98 [00:06<00:16,  4.31it/s, loss=-0.01381]\u001b[A\n",
      "Epoch 0:  27%|██████████████▌                                        | 26/98 [00:06<00:16,  4.31it/s, loss=-0.01803]\u001b[A\n",
      "Epoch 0:  28%|███████████████▏                                       | 27/98 [00:06<00:16,  4.38it/s, loss=-0.01803]\u001b[A\n",
      "Epoch 0:  28%|███████████████▏                                       | 27/98 [00:06<00:16,  4.38it/s, loss=-0.02099]\u001b[A\n",
      "Epoch 0:  29%|███████████████▋                                       | 28/98 [00:06<00:15,  4.46it/s, loss=-0.02099]\u001b[A\n",
      "Epoch 0:  29%|███████████████▋                                       | 28/98 [00:06<00:15,  4.46it/s, loss=-0.03782]\u001b[A\n",
      "Epoch 0:  30%|████████████████▎                                      | 29/98 [00:06<00:15,  4.50it/s, loss=-0.03782]\u001b[A\n",
      "Epoch 0:  30%|████████████████▎                                      | 29/98 [00:06<00:15,  4.50it/s, loss=-0.03900]\u001b[A\n",
      "Epoch 0:  31%|████████████████▊                                      | 30/98 [00:06<00:15,  4.51it/s, loss=-0.03900]\u001b[A\n",
      "Epoch 0:  31%|████████████████▊                                      | 30/98 [00:06<00:15,  4.51it/s, loss=-0.04334]\u001b[A\n",
      "Epoch 0:  32%|█████████████████▍                                     | 31/98 [00:07<00:15,  4.32it/s, loss=-0.04334]\u001b[A\n",
      "Epoch 0:  32%|█████████████████▍                                     | 31/98 [00:07<00:15,  4.32it/s, loss=-0.04762]\u001b[A\n",
      "Epoch 0:  33%|█████████████████▉                                     | 32/98 [00:07<00:15,  4.30it/s, loss=-0.04762]\u001b[A\n",
      "Epoch 0:  33%|█████████████████▉                                     | 32/98 [00:07<00:15,  4.30it/s, loss=-0.05418]\u001b[A\n",
      "Epoch 0:  34%|██████████████████▌                                    | 33/98 [00:07<00:15,  4.26it/s, loss=-0.05418]\u001b[A\n",
      "Epoch 0:  34%|██████████████████▌                                    | 33/98 [00:07<00:15,  4.26it/s, loss=-0.05424]\u001b[A\n",
      "Epoch 0:  35%|███████████████████                                    | 34/98 [00:07<00:14,  4.34it/s, loss=-0.05424]\u001b[A\n",
      "Epoch 0:  35%|███████████████████                                    | 34/98 [00:07<00:14,  4.34it/s, loss=-0.05400]\u001b[A\n",
      "Epoch 0:  36%|███████████████████▋                                   | 35/98 [00:08<00:14,  4.42it/s, loss=-0.05400]\u001b[A\n",
      "Epoch 0:  36%|███████████████████▋                                   | 35/98 [00:08<00:14,  4.42it/s, loss=-0.05602]\u001b[A\n",
      "Epoch 0:  37%|████████████████████▏                                  | 36/98 [00:08<00:14,  4.40it/s, loss=-0.05602]\u001b[A\n",
      "Epoch 0:  37%|████████████████████▏                                  | 36/98 [00:08<00:14,  4.40it/s, loss=-0.05426]\u001b[A\n",
      "Epoch 0:  38%|████████████████████▊                                  | 37/98 [00:08<00:13,  4.45it/s, loss=-0.05426]\u001b[A\n",
      "Epoch 0:  38%|████████████████████▊                                  | 37/98 [00:08<00:13,  4.45it/s, loss=-0.05424]\u001b[A\n",
      "Epoch 0:  39%|█████████████████████▎                                 | 38/98 [00:08<00:13,  4.49it/s, loss=-0.05424]\u001b[A\n",
      "Epoch 0:  39%|█████████████████████▎                                 | 38/98 [00:08<00:13,  4.49it/s, loss=-0.05671]\u001b[A\n",
      "Epoch 0:  40%|█████████████████████▉                                 | 39/98 [00:08<00:13,  4.53it/s, loss=-0.05671]\u001b[A\n",
      "Epoch 0:  40%|█████████████████████▉                                 | 39/98 [00:08<00:13,  4.53it/s, loss=-0.06324]\u001b[A\n",
      "Epoch 0:  41%|██████████████████████▍                                | 40/98 [00:09<00:13,  4.38it/s, loss=-0.06324]\u001b[A\n",
      "Epoch 0:  41%|██████████████████████▍                                | 40/98 [00:09<00:13,  4.38it/s, loss=-0.06381]\u001b[A\n",
      "Epoch 0:  42%|███████████████████████                                | 41/98 [00:09<00:12,  4.43it/s, loss=-0.06381]\u001b[A\n",
      "Epoch 0:  42%|███████████████████████                                | 41/98 [00:09<00:12,  4.43it/s, loss=-0.05727]\u001b[A\n",
      "Epoch 0:  43%|███████████████████████▌                               | 42/98 [00:09<00:12,  4.47it/s, loss=-0.05727]\u001b[A\n",
      "Epoch 0:  43%|███████████████████████▌                               | 42/98 [00:09<00:12,  4.47it/s, loss=-0.05823]\u001b[A\n",
      "Epoch 0:  44%|████████████████████████▏                              | 43/98 [00:09<00:12,  4.45it/s, loss=-0.05823]\u001b[A\n",
      "Epoch 0:  44%|████████████████████████▏                              | 43/98 [00:09<00:12,  4.45it/s, loss=-0.05873]\u001b[A\n",
      "Epoch 0:  45%|████████████████████████▋                              | 44/98 [00:10<00:11,  4.52it/s, loss=-0.05873]\u001b[A\n",
      "Epoch 0:  45%|████████████████████████▋                              | 44/98 [00:10<00:11,  4.52it/s, loss=-0.05880]\u001b[A\n",
      "Epoch 0:  46%|█████████████████████████▎                             | 45/98 [00:10<00:11,  4.43it/s, loss=-0.05880]\u001b[A\n",
      "Epoch 0:  46%|█████████████████████████▎                             | 45/98 [00:10<00:11,  4.43it/s, loss=-0.05665]\u001b[A\n",
      "Epoch 0:  47%|█████████████████████████▊                             | 46/98 [00:10<00:11,  4.45it/s, loss=-0.05665]\u001b[A\n",
      "Epoch 0:  47%|█████████████████████████▊                             | 46/98 [00:10<00:11,  4.45it/s, loss=-0.05831]\u001b[A\n",
      "Epoch 0:  48%|██████████████████████████▍                            | 47/98 [00:10<00:11,  4.46it/s, loss=-0.05831]\u001b[A\n",
      "Epoch 0:  48%|██████████████████████████▍                            | 47/98 [00:10<00:11,  4.46it/s, loss=-0.06038]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████▉                            | 48/98 [00:10<00:11,  4.39it/s, loss=-0.06038]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████▉                            | 48/98 [00:10<00:11,  4.39it/s, loss=-0.06275]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████▌                           | 49/98 [00:11<00:11,  4.34it/s, loss=-0.06275]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████▌                           | 49/98 [00:11<00:11,  4.34it/s, loss=-0.06051]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████                           | 50/98 [00:11<00:11,  4.33it/s, loss=-0.06051]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████                           | 50/98 [00:11<00:11,  4.33it/s, loss=-0.06107]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████▌                          | 51/98 [00:11<00:10,  4.38it/s, loss=-0.06107]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████▌                          | 51/98 [00:11<00:10,  4.38it/s, loss=-0.05898]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████▏                         | 52/98 [00:11<00:10,  4.45it/s, loss=-0.05898]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████▏                         | 52/98 [00:11<00:10,  4.45it/s, loss=-0.06155]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████▋                         | 53/98 [00:12<00:10,  4.36it/s, loss=-0.06155]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████▋                         | 53/98 [00:12<00:10,  4.36it/s, loss=-0.05870]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████▎                        | 54/98 [00:12<00:09,  4.40it/s, loss=-0.05870]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████▎                        | 54/98 [00:12<00:09,  4.40it/s, loss=-0.05836]\u001b[A\n",
      "Epoch 0:  56%|██████████████████████████████▊                        | 55/98 [00:12<00:09,  4.45it/s, loss=-0.05836]\u001b[A\n",
      "Epoch 0:  56%|██████████████████████████████▊                        | 55/98 [00:12<00:09,  4.45it/s, loss=-0.05885]\u001b[A\n",
      "Epoch 0:  57%|███████████████████████████████▍                       | 56/98 [00:12<00:09,  4.36it/s, loss=-0.05885]\u001b[A\n",
      "Epoch 0:  57%|███████████████████████████████▍                       | 56/98 [00:12<00:09,  4.36it/s, loss=-0.05990]\u001b[A\n",
      "Epoch 0:  58%|███████████████████████████████▉                       | 57/98 [00:13<00:09,  4.33it/s, loss=-0.05990]\u001b[A\n",
      "Epoch 0:  58%|███████████████████████████████▉                       | 57/98 [00:13<00:09,  4.33it/s, loss=-0.06085]\u001b[A\n",
      "Epoch 0:  59%|████████████████████████████████▌                      | 58/98 [00:13<00:09,  4.42it/s, loss=-0.06085]\u001b[A\n",
      "Epoch 0:  59%|████████████████████████████████▌                      | 58/98 [00:13<00:09,  4.42it/s, loss=-0.06246]\u001b[A\n",
      "Epoch 0:  60%|█████████████████████████████████                      | 59/98 [00:13<00:08,  4.46it/s, loss=-0.06246]\u001b[A\n",
      "Epoch 0:  60%|█████████████████████████████████                      | 59/98 [00:13<00:08,  4.46it/s, loss=-0.06349]\u001b[A\n",
      "Epoch 0:  61%|█████████████████████████████████▋                     | 60/98 [00:13<00:08,  4.51it/s, loss=-0.06349]\u001b[A\n",
      "Epoch 0:  61%|█████████████████████████████████▋                     | 60/98 [00:13<00:08,  4.51it/s, loss=-0.06248]\u001b[A\n",
      "Epoch 0:  62%|██████████████████████████████████▏                    | 61/98 [00:13<00:08,  4.52it/s, loss=-0.06248]\u001b[A\n",
      "Epoch 0:  62%|██████████████████████████████████▏                    | 61/98 [00:13<00:08,  4.52it/s, loss=-0.05815]\u001b[A\n",
      "Epoch 0:  63%|██████████████████████████████████▊                    | 62/98 [00:14<00:07,  4.59it/s, loss=-0.05815]\u001b[A\n",
      "Epoch 0:  63%|██████████████████████████████████▊                    | 62/98 [00:14<00:07,  4.59it/s, loss=-0.05701]\u001b[A\n",
      "Epoch 0:  64%|███████████████████████████████████▎                   | 63/98 [00:14<00:07,  4.47it/s, loss=-0.05701]\u001b[A\n",
      "Epoch 0:  64%|███████████████████████████████████▎                   | 63/98 [00:14<00:07,  4.47it/s, loss=-0.05575]\u001b[A\n",
      "Epoch 0:  65%|███████████████████████████████████▉                   | 64/98 [00:14<00:07,  4.51it/s, loss=-0.05575]\u001b[A\n",
      "Epoch 0:  65%|███████████████████████████████████▉                   | 64/98 [00:14<00:07,  4.51it/s, loss=-0.05668]\u001b[A\n",
      "Epoch 0:  66%|████████████████████████████████████▍                  | 65/98 [00:14<00:07,  4.54it/s, loss=-0.05668]\u001b[A\n",
      "Epoch 0:  66%|████████████████████████████████████▍                  | 65/98 [00:14<00:07,  4.54it/s, loss=-0.05286]\u001b[A\n",
      "Epoch 0:  67%|█████████████████████████████████████                  | 66/98 [00:15<00:07,  4.55it/s, loss=-0.05286]\u001b[A\n",
      "Epoch 0:  67%|█████████████████████████████████████                  | 66/98 [00:15<00:07,  4.55it/s, loss=-0.05090]\u001b[A\n",
      "Epoch 0:  68%|█████████████████████████████████████▌                 | 67/98 [00:15<00:06,  4.53it/s, loss=-0.05090]\u001b[A\n",
      "Epoch 0:  68%|█████████████████████████████████████▌                 | 67/98 [00:15<00:06,  4.53it/s, loss=-0.04796]\u001b[A\n",
      "Epoch 0:  69%|██████████████████████████████████████▏                | 68/98 [00:15<00:06,  4.54it/s, loss=-0.04796]\u001b[A\n",
      "Epoch 0:  69%|██████████████████████████████████████▏                | 68/98 [00:15<00:06,  4.54it/s, loss=-0.04857]\u001b[A\n",
      "Epoch 0:  70%|██████████████████████████████████████▋                | 69/98 [00:15<00:06,  4.47it/s, loss=-0.04857]\u001b[A\n",
      "Epoch 0:  70%|██████████████████████████████████████▋                | 69/98 [00:15<00:06,  4.47it/s, loss=-0.04661]\u001b[A\n",
      "Epoch 0:  71%|███████████████████████████████████████▎               | 70/98 [00:15<00:06,  4.50it/s, loss=-0.04661]\u001b[A\n",
      "Epoch 0:  71%|███████████████████████████████████████▎               | 70/98 [00:15<00:06,  4.50it/s, loss=-0.03880]\u001b[A\n",
      "Epoch 0:  72%|███████████████████████████████████████▊               | 71/98 [00:16<00:05,  4.53it/s, loss=-0.03880]\u001b[A\n",
      "Epoch 0:  72%|███████████████████████████████████████▊               | 71/98 [00:16<00:05,  4.53it/s, loss=-0.04406]\u001b[A\n",
      "Epoch 0:  73%|████████████████████████████████████████▍              | 72/98 [00:16<00:05,  4.48it/s, loss=-0.04406]\u001b[A\n",
      "Epoch 0:  73%|████████████████████████████████████████▍              | 72/98 [00:16<00:05,  4.48it/s, loss=-0.04191]\u001b[A\n",
      "Epoch 0:  74%|████████████████████████████████████████▉              | 73/98 [00:16<00:05,  4.51it/s, loss=-0.04191]\u001b[A\n",
      "Epoch 0:  74%|████████████████████████████████████████▉              | 73/98 [00:16<00:05,  4.51it/s, loss=-0.04444]\u001b[A\n",
      "Epoch 0:  76%|█████████████████████████████████████████▌             | 74/98 [00:16<00:05,  4.57it/s, loss=-0.04444]\u001b[A\n",
      "Epoch 0:  76%|█████████████████████████████████████████▌             | 74/98 [00:16<00:05,  4.57it/s, loss=-0.04613]\u001b[A\n",
      "Epoch 0:  77%|██████████████████████████████████████████             | 75/98 [00:17<00:05,  4.55it/s, loss=-0.04613]\u001b[A\n",
      "Epoch 0:  77%|██████████████████████████████████████████             | 75/98 [00:17<00:05,  4.55it/s, loss=-0.04384]\u001b[A\n",
      "Epoch 0:  78%|██████████████████████████████████████████▋            | 76/98 [00:17<00:04,  4.56it/s, loss=-0.04384]\u001b[A\n",
      "Epoch 0:  78%|██████████████████████████████████████████▋            | 76/98 [00:17<00:04,  4.56it/s, loss=-0.04159]\u001b[A\n",
      "Epoch 0:  79%|███████████████████████████████████████████▏           | 77/98 [00:17<00:04,  4.49it/s, loss=-0.04159]\u001b[A\n",
      "Epoch 0:  79%|███████████████████████████████████████████▏           | 77/98 [00:17<00:04,  4.49it/s, loss=-0.04313]\u001b[A\n",
      "Epoch 0:  80%|███████████████████████████████████████████▊           | 78/98 [00:17<00:04,  4.47it/s, loss=-0.04313]\u001b[A\n",
      "Epoch 0:  80%|███████████████████████████████████████████▊           | 78/98 [00:17<00:04,  4.47it/s, loss=-0.04730]\u001b[A\n",
      "Epoch 0:  81%|████████████████████████████████████████████▎          | 79/98 [00:17<00:04,  4.51it/s, loss=-0.04730]\u001b[A\n",
      "Epoch 0:  81%|████████████████████████████████████████████▎          | 79/98 [00:17<00:04,  4.51it/s, loss=-0.04816]\u001b[A\n",
      "Epoch 0:  82%|████████████████████████████████████████████▉          | 80/98 [00:18<00:04,  4.48it/s, loss=-0.04816]\u001b[A\n",
      "Epoch 0:  82%|████████████████████████████████████████████▉          | 80/98 [00:18<00:04,  4.48it/s, loss=-0.04816]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████████████████████████████▍         | 81/98 [00:18<00:03,  4.53it/s, loss=-0.04816]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████████████████████████████▍         | 81/98 [00:18<00:03,  4.53it/s, loss=-0.04705]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████████████████████         | 82/98 [00:18<00:03,  4.58it/s, loss=-0.04705]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████████████████████         | 82/98 [00:18<00:03,  4.58it/s, loss=-0.05002]\u001b[A\n",
      "Epoch 0:  85%|██████████████████████████████████████████████▌        | 83/98 [00:18<00:03,  4.57it/s, loss=-0.05002]\u001b[A\n",
      "Epoch 0:  85%|██████████████████████████████████████████████▌        | 83/98 [00:18<00:03,  4.57it/s, loss=-0.05110]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████████████████████▏       | 84/98 [00:18<00:03,  4.64it/s, loss=-0.05110]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████████████████████▏       | 84/98 [00:18<00:03,  4.64it/s, loss=-0.05004]\u001b[A\n",
      "Epoch 0:  87%|███████████████████████████████████████████████▋       | 85/98 [00:19<00:02,  4.62it/s, loss=-0.05004]\u001b[A\n",
      "Epoch 0:  87%|███████████████████████████████████████████████▋       | 85/98 [00:19<00:02,  4.62it/s, loss=-0.05266]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████████████████████▎      | 86/98 [00:19<00:02,  4.61it/s, loss=-0.05266]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████████████████████▎      | 86/98 [00:19<00:02,  4.61it/s, loss=-0.05332]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████████████████████▊      | 87/98 [00:19<00:02,  4.58it/s, loss=-0.05332]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████████████████████▊      | 87/98 [00:19<00:02,  4.58it/s, loss=-0.05210]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████████████████████▍     | 88/98 [00:19<00:02,  4.50it/s, loss=-0.05210]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████████████████████▍     | 88/98 [00:19<00:02,  4.50it/s, loss=-0.05288]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████████████████████▉     | 89/98 [00:20<00:01,  4.54it/s, loss=-0.05288]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████████████████████▉     | 89/98 [00:20<00:01,  4.54it/s, loss=-0.05336]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████████████████████▌    | 90/98 [00:20<00:01,  4.56it/s, loss=-0.05336]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████████████████████▌    | 90/98 [00:20<00:01,  4.56it/s, loss=-0.05547]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████████████████████████████████    | 91/98 [00:20<00:01,  4.48it/s, loss=-0.05547]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████████████████████████████████    | 91/98 [00:20<00:01,  4.48it/s, loss=-0.05264]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████████████████████████████████▋   | 92/98 [00:20<00:01,  4.53it/s, loss=-0.05264]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████████████████████████████████▋   | 92/98 [00:20<00:01,  4.53it/s, loss=-0.05190]\u001b[A\n",
      "Epoch 0:  95%|████████████████████████████████████████████████████▏  | 93/98 [00:20<00:01,  4.51it/s, loss=-0.05190]\u001b[A\n",
      "Epoch 0:  95%|████████████████████████████████████████████████████▏  | 93/98 [00:20<00:01,  4.51it/s, loss=-0.05252]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████████████████████████████████▊  | 94/98 [00:21<00:00,  4.47it/s, loss=-0.05252]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████████████████████████████████▊  | 94/98 [00:21<00:00,  4.47it/s, loss=-0.05550]\u001b[A\n",
      "Epoch 0:  97%|█████████████████████████████████████████████████████▎ | 95/98 [00:21<00:00,  4.36it/s, loss=-0.05550]\u001b[A\n",
      "Epoch 0:  97%|█████████████████████████████████████████████████████▎ | 95/98 [00:21<00:00,  4.36it/s, loss=-0.05846]\u001b[A\n",
      "Epoch 0:  98%|█████████████████████████████████████████████████████▉ | 96/98 [00:21<00:00,  4.38it/s, loss=-0.05846]\u001b[A\n",
      "Epoch 0:  98%|█████████████████████████████████████████████████████▉ | 96/98 [00:21<00:00,  4.38it/s, loss=-0.05953]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████████████████████████████████████▍| 97/98 [00:21<00:00,  4.38it/s, loss=-0.05953]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████████████████████████████████████▍| 97/98 [00:21<00:00,  4.38it/s, loss=-0.06075]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████████████████████████| 98/98 [00:22<00:00,  5.14it/s, loss=-0.06075]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████████████████████████| 98/98 [00:22<00:00,  5.14it/s, loss=-0.06229]\u001b[A\n",
      "Epoch 0: 100%|██████████████| 98/98 [00:37<00:00,  5.14it/s, loss=-0.06229, test_loss=-0.09673, train_loss=-0.09638]\u001b[A\n",
      "Epoch 0: 100%|██████████████| 98/98 [00:37<00:00,  2.63it/s, loss=-0.06229, test_loss=-0.09673, train_loss=-0.09638]\u001b[A\n",
      "\n",
      "Epoch 1:   0%|                                                                               | 0/98 [00:00<?, ?it/s]\u001b[AC:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "\n",
      "Epoch 1:   1%|▋                                                                      | 1/98 [00:00<00:19,  4.93it/s]\u001b[A\n",
      "Epoch 1:   1%|▌                                                       | 1/98 [00:00<00:19,  4.93it/s, loss=-0.19940]\u001b[A\n",
      "Epoch 1:   2%|█▏                                                      | 2/98 [00:00<00:21,  4.51it/s, loss=-0.19940]\u001b[A\n",
      "Epoch 1:   2%|█▏                                                      | 2/98 [00:00<00:21,  4.51it/s, loss=-0.11653]\u001b[A\n",
      "Epoch 1:   3%|█▋                                                      | 3/98 [00:00<00:20,  4.60it/s, loss=-0.11653]\u001b[A\n",
      "Epoch 1:   3%|█▋                                                      | 3/98 [00:00<00:20,  4.60it/s, loss=-0.10080]\u001b[A\n",
      "Epoch 1:   4%|██▎                                                     | 4/98 [00:00<00:21,  4.41it/s, loss=-0.10080]\u001b[A\n",
      "Epoch 1:   4%|██▎                                                     | 4/98 [00:00<00:21,  4.41it/s, loss=-0.13108]\u001b[A\n",
      "Epoch 1:   5%|██▊                                                     | 5/98 [00:01<00:20,  4.49it/s, loss=-0.13108]\u001b[A\n",
      "Epoch 1:   5%|██▊                                                     | 5/98 [00:01<00:20,  4.49it/s, loss=-0.13125]\u001b[A\n",
      "Epoch 1:   6%|███▍                                                    | 6/98 [00:01<00:20,  4.54it/s, loss=-0.13125]\u001b[A\n",
      "Epoch 1:   6%|███▍                                                    | 6/98 [00:01<00:20,  4.54it/s, loss=-0.10262]\u001b[A\n",
      "Epoch 1:   7%|████                                                    | 7/98 [00:01<00:20,  4.54it/s, loss=-0.10262]\u001b[A\n",
      "Epoch 1:   7%|████                                                    | 7/98 [00:01<00:20,  4.54it/s, loss=-0.09243]\u001b[A\n",
      "Epoch 1:   8%|████▌                                                   | 8/98 [00:01<00:21,  4.15it/s, loss=-0.09243]\u001b[A\n",
      "Epoch 1:   8%|████▌                                                   | 8/98 [00:01<00:21,  4.15it/s, loss=-0.09186]\u001b[A\n",
      "Epoch 1:   9%|█████▏                                                  | 9/98 [00:02<00:22,  3.88it/s, loss=-0.09186]\u001b[A\n",
      "Epoch 1:   9%|█████▏                                                  | 9/98 [00:02<00:22,  3.88it/s, loss=-0.10560]\u001b[A\n",
      "Epoch 1:  10%|█████▌                                                 | 10/98 [00:02<00:21,  4.04it/s, loss=-0.10560]\u001b[A\n",
      "Epoch 1:  10%|█████▌                                                 | 10/98 [00:02<00:21,  4.04it/s, loss=-0.08303]\u001b[A\n",
      "Epoch 1:  11%|██████▏                                                | 11/98 [00:02<00:20,  4.23it/s, loss=-0.08303]\u001b[A\n",
      "Epoch 1:  11%|██████▏                                                | 11/98 [00:02<00:20,  4.23it/s, loss=-0.06733]\u001b[A\n",
      "Epoch 1:  12%|██████▋                                                | 12/98 [00:02<00:19,  4.39it/s, loss=-0.06733]\u001b[A\n",
      "Epoch 1:  12%|██████▋                                                | 12/98 [00:02<00:19,  4.39it/s, loss=-0.05072]\u001b[A\n",
      "Epoch 1:  13%|███████▎                                               | 13/98 [00:02<00:19,  4.41it/s, loss=-0.05072]\u001b[A\n",
      "Epoch 1:  13%|███████▎                                               | 13/98 [00:02<00:19,  4.41it/s, loss=-0.03562]\u001b[A\n",
      "Epoch 1:  14%|███████▊                                               | 14/98 [00:03<00:18,  4.57it/s, loss=-0.03562]\u001b[A\n",
      "Epoch 1:  14%|███████▊                                               | 14/98 [00:03<00:18,  4.57it/s, loss=-0.03340]\u001b[A\n",
      "Epoch 1:  15%|████████▍                                              | 15/98 [00:03<00:18,  4.59it/s, loss=-0.03340]\u001b[A\n",
      "Epoch 1:  15%|████████▍                                              | 15/98 [00:03<00:18,  4.59it/s, loss=-0.02737]\u001b[A\n",
      "Epoch 1:  16%|████████▉                                              | 16/98 [00:03<00:17,  4.68it/s, loss=-0.02737]\u001b[A\n",
      "Epoch 1:  16%|████████▉                                              | 16/98 [00:03<00:17,  4.68it/s, loss=-0.02280]\u001b[A\n",
      "Epoch 1:  17%|█████████▌                                             | 17/98 [00:03<00:17,  4.68it/s, loss=-0.02280]\u001b[A\n",
      "Epoch 1:  17%|█████████▌                                             | 17/98 [00:03<00:17,  4.68it/s, loss=-0.03387]\u001b[A\n",
      "Epoch 1:  18%|██████████                                             | 18/98 [00:04<00:17,  4.56it/s, loss=-0.03387]\u001b[A\n",
      "Epoch 1:  18%|██████████                                             | 18/98 [00:04<00:17,  4.56it/s, loss=-0.04556]\u001b[A\n",
      "Epoch 1:  19%|██████████▋                                            | 19/98 [00:04<00:17,  4.55it/s, loss=-0.04556]\u001b[A\n",
      "Epoch 1:  19%|██████████▋                                            | 19/98 [00:04<00:17,  4.55it/s, loss=-0.05891]\u001b[A\n",
      "Epoch 1:  20%|███████████▏                                           | 20/98 [00:04<00:17,  4.56it/s, loss=-0.05891]\u001b[A\n",
      "Epoch 1:  20%|███████████▏                                           | 20/98 [00:04<00:17,  4.56it/s, loss=-0.07843]\u001b[A\n",
      "Epoch 1:  21%|███████████▊                                           | 21/98 [00:04<00:16,  4.64it/s, loss=-0.07843]\u001b[A\n",
      "Epoch 1:  21%|███████████▊                                           | 21/98 [00:04<00:16,  4.64it/s, loss=-0.08653]\u001b[A\n",
      "Epoch 1:  22%|████████████▎                                          | 22/98 [00:04<00:16,  4.73it/s, loss=-0.08653]\u001b[A\n",
      "Epoch 1:  22%|████████████▎                                          | 22/98 [00:04<00:16,  4.73it/s, loss=-0.08083]\u001b[A\n",
      "Epoch 1:  23%|████████████▉                                          | 23/98 [00:05<00:16,  4.63it/s, loss=-0.08083]\u001b[A\n",
      "Epoch 1:  23%|████████████▉                                          | 23/98 [00:05<00:16,  4.63it/s, loss=-0.07324]\u001b[A\n",
      "Epoch 1:  24%|█████████████▍                                         | 24/98 [00:05<00:15,  4.69it/s, loss=-0.07324]\u001b[A\n",
      "Epoch 1:  24%|█████████████▍                                         | 24/98 [00:05<00:15,  4.69it/s, loss=-0.08556]\u001b[A\n",
      "Epoch 1:  26%|██████████████                                         | 25/98 [00:05<00:15,  4.71it/s, loss=-0.08556]\u001b[A\n",
      "Epoch 1:  26%|██████████████                                         | 25/98 [00:05<00:15,  4.71it/s, loss=-0.07736]\u001b[A\n",
      "Epoch 1:  27%|██████████████▌                                        | 26/98 [00:05<00:15,  4.77it/s, loss=-0.07736]\u001b[A\n",
      "Epoch 1:  27%|██████████████▌                                        | 26/98 [00:05<00:15,  4.77it/s, loss=-0.08140]\u001b[A\n",
      "Epoch 1:  28%|███████████████▏                                       | 27/98 [00:05<00:14,  4.77it/s, loss=-0.08140]\u001b[A\n",
      "Epoch 1:  28%|███████████████▏                                       | 27/98 [00:05<00:14,  4.77it/s, loss=-0.08256]\u001b[A\n",
      "Epoch 1:  29%|███████████████▋                                       | 28/98 [00:06<00:15,  4.59it/s, loss=-0.08256]\u001b[A\n",
      "Epoch 1:  29%|███████████████▋                                       | 28/98 [00:06<00:15,  4.59it/s, loss=-0.09615]\u001b[A\n",
      "Epoch 1:  30%|████████████████▎                                      | 29/98 [00:06<00:15,  4.59it/s, loss=-0.09615]\u001b[A\n",
      "Epoch 1:  30%|████████████████▎                                      | 29/98 [00:06<00:15,  4.59it/s, loss=-0.09774]\u001b[A\n",
      "Epoch 1:  31%|████████████████▊                                      | 30/98 [00:06<00:14,  4.62it/s, loss=-0.09774]\u001b[A\n",
      "Epoch 1:  31%|████████████████▊                                      | 30/98 [00:06<00:14,  4.62it/s, loss=-0.09999]\u001b[A\n",
      "Epoch 1:  32%|█████████████████▍                                     | 31/98 [00:06<00:14,  4.68it/s, loss=-0.09999]\u001b[A\n",
      "Epoch 1:  32%|█████████████████▍                                     | 31/98 [00:06<00:14,  4.68it/s, loss=-0.10613]\u001b[A\n",
      "Epoch 1:  33%|█████████████████▉                                     | 32/98 [00:07<00:14,  4.46it/s, loss=-0.10613]\u001b[A\n",
      "Epoch 1:  33%|█████████████████▉                                     | 32/98 [00:07<00:14,  4.46it/s, loss=-0.10878]\u001b[A\n",
      "Epoch 1:  34%|██████████████████▌                                    | 33/98 [00:07<00:15,  4.19it/s, loss=-0.10878]\u001b[A\n",
      "Epoch 1:  34%|██████████████████▌                                    | 33/98 [00:07<00:15,  4.19it/s, loss=-0.11123]\u001b[A\n",
      "Epoch 1:  35%|███████████████████                                    | 34/98 [00:07<00:14,  4.29it/s, loss=-0.11123]\u001b[A\n",
      "Epoch 1:  35%|███████████████████                                    | 34/98 [00:07<00:14,  4.29it/s, loss=-0.11462]\u001b[A\n",
      "Epoch 1:  36%|███████████████████▋                                   | 35/98 [00:07<00:14,  4.28it/s, loss=-0.11462]\u001b[A\n",
      "Epoch 1:  36%|███████████████████▋                                   | 35/98 [00:07<00:14,  4.28it/s, loss=-0.11436]\u001b[A\n",
      "Epoch 1:  37%|████████████████████▏                                  | 36/98 [00:08<00:14,  4.34it/s, loss=-0.11436]\u001b[A\n",
      "Epoch 1:  37%|████████████████████▏                                  | 36/98 [00:08<00:14,  4.34it/s, loss=-0.11361]\u001b[A\n",
      "Epoch 1:  38%|████████████████████▊                                  | 37/98 [00:08<00:14,  4.35it/s, loss=-0.11361]\u001b[A\n",
      "Epoch 1:  38%|████████████████████▊                                  | 37/98 [00:08<00:14,  4.35it/s, loss=-0.11040]\u001b[A\n",
      "Epoch 1:  39%|█████████████████████▎                                 | 38/98 [00:08<00:13,  4.32it/s, loss=-0.11040]\u001b[A\n",
      "Epoch 1:  39%|█████████████████████▎                                 | 38/98 [00:08<00:13,  4.32it/s, loss=-0.11481]\u001b[A\n",
      "Epoch 1:  40%|█████████████████████▉                                 | 39/98 [00:08<00:14,  4.04it/s, loss=-0.11481]\u001b[A\n",
      "Epoch 1:  40%|█████████████████████▉                                 | 39/98 [00:08<00:14,  4.04it/s, loss=-0.12167]\u001b[A\n",
      "Epoch 1:  41%|██████████████████████▍                                | 40/98 [00:09<00:14,  3.88it/s, loss=-0.12167]\u001b[A\n",
      "Epoch 1:  41%|██████████████████████▍                                | 40/98 [00:09<00:14,  3.88it/s, loss=-0.12291]\u001b[A\n",
      "Epoch 1:  42%|███████████████████████                                | 41/98 [00:09<00:14,  3.93it/s, loss=-0.12291]\u001b[A\n",
      "Epoch 1:  42%|███████████████████████                                | 41/98 [00:09<00:14,  3.93it/s, loss=-0.11629]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████▌                               | 42/98 [00:09<00:14,  3.97it/s, loss=-0.11629]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████▌                               | 42/98 [00:09<00:14,  3.97it/s, loss=-0.11744]\u001b[A\n",
      "Epoch 1:  44%|████████████████████████▏                              | 43/98 [00:09<00:13,  4.05it/s, loss=-0.11744]\u001b[A\n",
      "Epoch 1:  44%|████████████████████████▏                              | 43/98 [00:09<00:13,  4.05it/s, loss=-0.11667]\u001b[A\n",
      "Epoch 1:  45%|████████████████████████▋                              | 44/98 [00:10<00:12,  4.20it/s, loss=-0.11667]\u001b[A\n",
      "Epoch 1:  45%|████████████████████████▋                              | 44/98 [00:10<00:12,  4.20it/s, loss=-0.11853]\u001b[A\n",
      "Epoch 1:  46%|█████████████████████████▎                             | 45/98 [00:10<00:12,  4.35it/s, loss=-0.11853]\u001b[A\n",
      "Epoch 1:  46%|█████████████████████████▎                             | 45/98 [00:10<00:12,  4.35it/s, loss=-0.11501]\u001b[A\n",
      "Epoch 1:  47%|█████████████████████████▊                             | 46/98 [00:10<00:11,  4.46it/s, loss=-0.11501]\u001b[A\n",
      "Epoch 1:  47%|█████████████████████████▊                             | 46/98 [00:10<00:11,  4.46it/s, loss=-0.11769]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████▍                            | 47/98 [00:10<00:11,  4.43it/s, loss=-0.11769]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████▍                            | 47/98 [00:10<00:11,  4.43it/s, loss=-0.11937]\u001b[A\n",
      "Epoch 1:  49%|██████████████████████████▉                            | 48/98 [00:10<00:10,  4.55it/s, loss=-0.11937]\u001b[A\n",
      "Epoch 1:  49%|██████████████████████████▉                            | 48/98 [00:10<00:10,  4.55it/s, loss=-0.12285]\u001b[A\n",
      "Epoch 1:  50%|███████████████████████████▌                           | 49/98 [00:11<00:10,  4.63it/s, loss=-0.12285]\u001b[A\n",
      "Epoch 1:  50%|███████████████████████████▌                           | 49/98 [00:11<00:10,  4.63it/s, loss=-0.12069]\u001b[A\n",
      "Epoch 1:  51%|████████████████████████████                           | 50/98 [00:11<00:10,  4.63it/s, loss=-0.12069]\u001b[A\n",
      "Epoch 1:  51%|████████████████████████████                           | 50/98 [00:11<00:10,  4.63it/s, loss=-0.11966]\u001b[A\n",
      "Epoch 1:  52%|████████████████████████████▌                          | 51/98 [00:11<00:10,  4.68it/s, loss=-0.11966]\u001b[A\n",
      "Epoch 1:  52%|████████████████████████████▌                          | 51/98 [00:11<00:10,  4.68it/s, loss=-0.11702]\u001b[A\n",
      "Epoch 1:  53%|█████████████████████████████▏                         | 52/98 [00:11<00:09,  4.65it/s, loss=-0.11702]\u001b[A\n",
      "Epoch 1:  53%|█████████████████████████████▏                         | 52/98 [00:11<00:09,  4.65it/s, loss=-0.12016]\u001b[A\n",
      "Epoch 1:  54%|█████████████████████████████▋                         | 53/98 [00:11<00:09,  4.73it/s, loss=-0.12016]\u001b[A\n",
      "Epoch 1:  54%|█████████████████████████████▋                         | 53/98 [00:11<00:09,  4.73it/s, loss=-0.11889]\u001b[A\n",
      "Epoch 1:  55%|██████████████████████████████▎                        | 54/98 [00:12<00:09,  4.66it/s, loss=-0.11889]\u001b[A\n",
      "Epoch 1:  55%|██████████████████████████████▎                        | 54/98 [00:12<00:09,  4.66it/s, loss=-0.11831]\u001b[A\n",
      "Epoch 1:  56%|██████████████████████████████▊                        | 55/98 [00:12<00:09,  4.55it/s, loss=-0.11831]\u001b[A\n",
      "Epoch 1:  56%|██████████████████████████████▊                        | 55/98 [00:12<00:09,  4.55it/s, loss=-0.11844]\u001b[A\n",
      "Epoch 1:  57%|███████████████████████████████▍                       | 56/98 [00:12<00:09,  4.57it/s, loss=-0.11844]\u001b[A\n",
      "Epoch 1:  57%|███████████████████████████████▍                       | 56/98 [00:12<00:09,  4.57it/s, loss=-0.12226]\u001b[A\n",
      "Epoch 1:  58%|███████████████████████████████▉                       | 57/98 [00:12<00:08,  4.62it/s, loss=-0.12226]\u001b[A\n",
      "Epoch 1:  58%|███████████████████████████████▉                       | 57/98 [00:12<00:08,  4.62it/s, loss=-0.12108]\u001b[A\n",
      "Epoch 1:  59%|████████████████████████████████▌                      | 58/98 [00:13<00:08,  4.67it/s, loss=-0.12108]\u001b[A\n",
      "Epoch 1:  59%|████████████████████████████████▌                      | 58/98 [00:13<00:08,  4.67it/s, loss=-0.12231]\u001b[A\n",
      "Epoch 1:  60%|█████████████████████████████████                      | 59/98 [00:13<00:08,  4.60it/s, loss=-0.12231]\u001b[A\n",
      "Epoch 1:  60%|█████████████████████████████████                      | 59/98 [00:13<00:08,  4.60it/s, loss=-0.12225]\u001b[A\n",
      "Epoch 1:  61%|█████████████████████████████████▋                     | 60/98 [00:13<00:08,  4.60it/s, loss=-0.12225]\u001b[A\n",
      "Epoch 1:  61%|█████████████████████████████████▋                     | 60/98 [00:13<00:08,  4.60it/s, loss=-0.12077]\u001b[A\n",
      "Epoch 1:  62%|██████████████████████████████████▏                    | 61/98 [00:13<00:08,  4.54it/s, loss=-0.12077]\u001b[A\n",
      "Epoch 1:  62%|██████████████████████████████████▏                    | 61/98 [00:13<00:08,  4.54it/s, loss=-0.11578]\u001b[A\n",
      "Epoch 1:  63%|██████████████████████████████████▊                    | 62/98 [00:13<00:07,  4.60it/s, loss=-0.11578]\u001b[A\n",
      "Epoch 1:  63%|██████████████████████████████████▊                    | 62/98 [00:13<00:07,  4.60it/s, loss=-0.11534]\u001b[A\n",
      "Epoch 1:  64%|███████████████████████████████████▎                   | 63/98 [00:14<00:07,  4.59it/s, loss=-0.11534]\u001b[A\n",
      "Epoch 1:  64%|███████████████████████████████████▎                   | 63/98 [00:14<00:07,  4.59it/s, loss=-0.11352]\u001b[A\n",
      "Epoch 1:  65%|███████████████████████████████████▉                   | 64/98 [00:14<00:07,  4.62it/s, loss=-0.11352]\u001b[A\n",
      "Epoch 1:  65%|███████████████████████████████████▉                   | 64/98 [00:14<00:07,  4.62it/s, loss=-0.11255]\u001b[A\n",
      "Epoch 1:  66%|████████████████████████████████████▍                  | 65/98 [00:14<00:07,  4.69it/s, loss=-0.11255]\u001b[A\n",
      "Epoch 1:  66%|████████████████████████████████████▍                  | 65/98 [00:14<00:07,  4.69it/s, loss=-0.11006]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████████████████████                  | 66/98 [00:14<00:06,  4.71it/s, loss=-0.11006]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████████████████████                  | 66/98 [00:14<00:06,  4.71it/s, loss=-0.10813]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████████████████████▌                 | 67/98 [00:14<00:06,  4.63it/s, loss=-0.10813]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████████████████████▌                 | 67/98 [00:14<00:06,  4.63it/s, loss=-0.10399]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████████████████████▏                | 68/98 [00:15<00:06,  4.66it/s, loss=-0.10399]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████████████████████▏                | 68/98 [00:15<00:06,  4.66it/s, loss=-0.10378]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████▋                | 69/98 [00:15<00:06,  4.71it/s, loss=-0.10378]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████▋                | 69/98 [00:15<00:06,  4.71it/s, loss=-0.10056]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████████▎               | 70/98 [00:15<00:05,  4.70it/s, loss=-0.10056]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████████▎               | 70/98 [00:15<00:05,  4.70it/s, loss=-0.09673]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████████▊               | 71/98 [00:15<00:05,  4.66it/s, loss=-0.09673]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████████▊               | 71/98 [00:15<00:05,  4.66it/s, loss=-0.10196]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████████▍              | 72/98 [00:16<00:05,  4.72it/s, loss=-0.10196]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████████▍              | 72/98 [00:16<00:05,  4.72it/s, loss=-0.10040]\u001b[A\n",
      "Epoch 1:  74%|████████████████████████████████████████▉              | 73/98 [00:16<00:05,  4.72it/s, loss=-0.10040]\u001b[A\n",
      "Epoch 1:  74%|████████████████████████████████████████▉              | 73/98 [00:16<00:05,  4.72it/s, loss=-0.10257]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████████████████████▌             | 74/98 [00:16<00:05,  4.74it/s, loss=-0.10257]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████████████████████▌             | 74/98 [00:16<00:05,  4.74it/s, loss=-0.10354]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████████             | 75/98 [00:16<00:04,  4.64it/s, loss=-0.10354]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████████             | 75/98 [00:16<00:04,  4.64it/s, loss=-0.10127]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████████████████████▋            | 76/98 [00:16<00:04,  4.61it/s, loss=-0.10127]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████████████████████▋            | 76/98 [00:16<00:04,  4.61it/s, loss=-0.09861]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████████▏           | 77/98 [00:17<00:04,  4.65it/s, loss=-0.09861]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████████▏           | 77/98 [00:17<00:04,  4.65it/s, loss=-0.09886]\u001b[A\n",
      "Epoch 1:  80%|███████████████████████████████████████████▊           | 78/98 [00:17<00:04,  4.69it/s, loss=-0.09886]\u001b[A\n",
      "Epoch 1:  80%|███████████████████████████████████████████▊           | 78/98 [00:17<00:04,  4.69it/s, loss=-0.10156]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████████▎          | 79/98 [00:17<00:04,  4.61it/s, loss=-0.10156]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████████▎          | 79/98 [00:17<00:04,  4.61it/s, loss=-0.10105]\u001b[A\n",
      "Epoch 1:  82%|████████████████████████████████████████████▉          | 80/98 [00:17<00:03,  4.61it/s, loss=-0.10105]\u001b[A\n",
      "Epoch 1:  82%|████████████████████████████████████████████▉          | 80/98 [00:17<00:03,  4.61it/s, loss=-0.10180]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████████▍         | 81/98 [00:17<00:03,  4.67it/s, loss=-0.10180]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████████▍         | 81/98 [00:17<00:03,  4.67it/s, loss=-0.10096]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████████         | 82/98 [00:18<00:03,  4.71it/s, loss=-0.10096]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████████         | 82/98 [00:18<00:03,  4.71it/s, loss=-0.10344]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████████▌        | 83/98 [00:18<00:03,  4.58it/s, loss=-0.10344]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████████▌        | 83/98 [00:18<00:03,  4.58it/s, loss=-0.10380]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████████████████████████▏       | 84/98 [00:18<00:03,  4.62it/s, loss=-0.10380]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████████████████████████▏       | 84/98 [00:18<00:03,  4.62it/s, loss=-0.10345]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████████▋       | 85/98 [00:18<00:02,  4.64it/s, loss=-0.10345]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████████▋       | 85/98 [00:18<00:02,  4.64it/s, loss=-0.10590]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████████▎      | 86/98 [00:19<00:02,  4.67it/s, loss=-0.10590]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████████▎      | 86/98 [00:19<00:02,  4.67it/s, loss=-0.10626]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████████▊      | 87/98 [00:19<00:02,  4.56it/s, loss=-0.10626]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████████▊      | 87/98 [00:19<00:02,  4.56it/s, loss=-0.10414]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████████▍     | 88/98 [00:19<00:02,  4.68it/s, loss=-0.10414]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████████▍     | 88/98 [00:19<00:02,  4.68it/s, loss=-0.10452]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████▉     | 89/98 [00:19<00:01,  4.73it/s, loss=-0.10452]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████▉     | 89/98 [00:19<00:01,  4.73it/s, loss=-0.10409]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████████▌    | 90/98 [00:19<00:01,  4.64it/s, loss=-0.10409]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████████▌    | 90/98 [00:19<00:01,  4.64it/s, loss=-0.10473]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████████    | 91/98 [00:20<00:01,  4.48it/s, loss=-0.10473]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████████    | 91/98 [00:20<00:01,  4.48it/s, loss=-0.10150]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████████▋   | 92/98 [00:20<00:01,  4.57it/s, loss=-0.10150]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████████▋   | 92/98 [00:20<00:01,  4.57it/s, loss=-0.10086]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████████▏  | 93/98 [00:20<00:01,  4.44it/s, loss=-0.10086]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████████▏  | 93/98 [00:20<00:01,  4.44it/s, loss=-0.10101]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████████▊  | 94/98 [00:20<00:00,  4.49it/s, loss=-0.10101]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████████▊  | 94/98 [00:20<00:00,  4.49it/s, loss=-0.10468]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████████████████████████████████████▎ | 95/98 [00:21<00:00,  4.45it/s, loss=-0.10468]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████████████████████████████████████▎ | 95/98 [00:21<00:00,  4.45it/s, loss=-0.10759]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████████████████████████▉ | 96/98 [00:21<00:00,  4.52it/s, loss=-0.10759]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████████████████████████▉ | 96/98 [00:21<00:00,  4.52it/s, loss=-0.10723]\u001b[A\n",
      "Epoch 1:  99%|██████████████████████████████████████████████████████▍| 97/98 [00:21<00:00,  4.39it/s, loss=-0.10723]\u001b[A\n",
      "Epoch 1:  99%|██████████████████████████████████████████████████████▍| 97/98 [00:21<00:00,  4.39it/s, loss=-0.10761]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████| 98/98 [00:21<00:00,  4.39it/s, loss=-0.10776]\u001b[A\n",
      "Epoch 1: 100%|██████████████| 98/98 [00:36<00:00,  4.39it/s, loss=-0.10776, test_loss=-0.11515, train_loss=-0.14363]\u001b[A\n",
      "Epoch 1: 100%|██████████████| 98/98 [00:36<00:00,  2.71it/s, loss=-0.10776, test_loss=-0.11515, train_loss=-0.14363]\u001b[A\n",
      "\n",
      "Epoch 2:   0%|                                                                               | 0/98 [00:00<?, ?it/s]\u001b[AC:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "\n",
      "Epoch 2:   1%|▋                                                                      | 1/98 [00:00<00:21,  4.43it/s]\u001b[A\n",
      "Epoch 2:   1%|▌                                                       | 1/98 [00:00<00:21,  4.43it/s, loss=-0.16525]\u001b[A\n",
      "Epoch 2:   2%|█▏                                                      | 2/98 [00:00<00:20,  4.58it/s, loss=-0.16525]\u001b[A\n",
      "Epoch 2:   2%|█▏                                                      | 2/98 [00:00<00:20,  4.58it/s, loss=-0.10500]\u001b[A\n",
      "Epoch 2:   3%|█▋                                                      | 3/98 [00:00<00:21,  4.34it/s, loss=-0.10500]\u001b[A\n",
      "Epoch 2:   3%|█▋                                                      | 3/98 [00:00<00:21,  4.34it/s, loss=-0.07757]\u001b[A\n",
      "Epoch 2:   4%|██▎                                                     | 4/98 [00:00<00:20,  4.52it/s, loss=-0.07757]\u001b[A\n",
      "Epoch 128:  50%|██████████████████████████▌                          | 49/98 [07:20<07:20,  9.00s/it, loss=-0.81073]\u001b[A\n",
      "\n",
      "Epoch 2:   5%|██▊                                                     | 5/98 [00:01<00:31,  2.91it/s, loss=-0.09638]\u001b[A\n",
      "Epoch 2:   5%|██▊                                                     | 5/98 [00:01<00:31,  2.91it/s, loss=-0.11940]\u001b[A\n",
      "Epoch 2:   6%|███▍                                                    | 6/98 [00:01<00:27,  3.36it/s, loss=-0.11940]\u001b[A\n",
      "Epoch 2:   6%|███▍                                                    | 6/98 [00:01<00:27,  3.36it/s, loss=-0.11975]\u001b[A\n",
      "Epoch 2:   7%|████                                                    | 7/98 [00:01<00:24,  3.65it/s, loss=-0.11975]\u001b[A\n",
      "Epoch 2:   7%|████                                                    | 7/98 [00:01<00:24,  3.65it/s, loss=-0.10817]\u001b[A\n",
      "Epoch 2:   8%|████▌                                                   | 8/98 [00:02<00:23,  3.86it/s, loss=-0.10817]\u001b[A\n",
      "Epoch 2:   8%|████▌                                                   | 8/98 [00:02<00:23,  3.86it/s, loss=-0.11251]\u001b[A\n",
      "Epoch 2:   9%|█████▏                                                  | 9/98 [00:02<00:21,  4.06it/s, loss=-0.11251]\u001b[A\n",
      "Epoch 2:   9%|█████▏                                                  | 9/98 [00:02<00:21,  4.06it/s, loss=-0.13266]\u001b[A\n",
      "Epoch 2:  10%|█████▌                                                 | 10/98 [00:02<00:20,  4.23it/s, loss=-0.13266]\u001b[A\n",
      "Epoch 2:  10%|█████▌                                                 | 10/98 [00:02<00:20,  4.23it/s, loss=-0.10694]\u001b[A\n",
      "Epoch 2:  11%|██████▏                                                | 11/98 [00:02<00:20,  4.35it/s, loss=-0.10694]\u001b[A\n",
      "Epoch 2:  11%|██████▏                                                | 11/98 [00:02<00:20,  4.35it/s, loss=-0.10002]\u001b[A\n",
      "Epoch 2:  12%|██████▋                                                | 12/98 [00:02<00:19,  4.43it/s, loss=-0.10002]\u001b[A\n",
      "Epoch 2:  12%|██████▋                                                | 12/98 [00:02<00:19,  4.43it/s, loss=-0.07533]\u001b[A\n",
      "Epoch 2:  13%|███████▎                                               | 13/98 [00:03<00:18,  4.53it/s, loss=-0.07533]\u001b[A\n",
      "Epoch 2:  13%|███████▎                                               | 13/98 [00:03<00:18,  4.53it/s, loss=-0.06249]\u001b[A\n",
      "Epoch 2:  14%|███████▊                                               | 14/98 [00:03<00:18,  4.54it/s, loss=-0.06249]\u001b[A\n",
      "Epoch 2:  14%|███████▊                                               | 14/98 [00:03<00:18,  4.54it/s, loss=-0.05849]\u001b[A\n",
      "Epoch 2:  15%|████████▍                                              | 15/98 [00:03<00:18,  4.58it/s, loss=-0.05849]\u001b[A\n",
      "Epoch 2:  15%|████████▍                                              | 15/98 [00:03<00:18,  4.58it/s, loss=-0.05114]\u001b[A\n",
      "Epoch 2:  16%|████████▉                                              | 16/98 [00:03<00:17,  4.61it/s, loss=-0.05114]\u001b[A\n",
      "Epoch 2:  16%|████████▉                                              | 16/98 [00:03<00:17,  4.61it/s, loss=-0.04765]\u001b[A\n",
      "Epoch 2:  17%|█████████▌                                             | 17/98 [00:04<00:17,  4.57it/s, loss=-0.04765]\u001b[A\n",
      "Epoch 2:  17%|█████████▌                                             | 17/98 [00:04<00:17,  4.57it/s, loss=-0.05505]\u001b[A\n",
      "Epoch 2:  18%|██████████                                             | 18/98 [00:04<00:17,  4.55it/s, loss=-0.05505]\u001b[A\n",
      "Epoch 2:  18%|██████████                                             | 18/98 [00:04<00:17,  4.55it/s, loss=-0.06602]\u001b[A\n",
      "Epoch 2:  19%|██████████▋                                            | 19/98 [00:04<00:17,  4.58it/s, loss=-0.06602]\u001b[A\n",
      "Epoch 2:  19%|██████████▋                                            | 19/98 [00:04<00:17,  4.58it/s, loss=-0.07807]\u001b[A\n",
      "Epoch 2:  20%|███████████▏                                           | 20/98 [00:04<00:17,  4.52it/s, loss=-0.07807]\u001b[A\n",
      "Epoch 2:  20%|███████████▏                                           | 20/98 [00:04<00:17,  4.52it/s, loss=-0.09621]\u001b[A\n",
      "Epoch 2:  21%|███████████▊                                           | 21/98 [00:04<00:17,  4.47it/s, loss=-0.09621]\u001b[A\n",
      "Epoch 2:  21%|███████████▊                                           | 21/98 [00:04<00:17,  4.47it/s, loss=-0.10340]\u001b[A\n",
      "Epoch 2:  22%|████████████▎                                          | 22/98 [00:05<00:16,  4.55it/s, loss=-0.10340]\u001b[A\n",
      "Epoch 2:  22%|████████████▎                                          | 22/98 [00:05<00:16,  4.55it/s, loss=-0.09793]\u001b[A\n",
      "Epoch 2:  23%|████████████▉                                          | 23/98 [00:05<00:16,  4.48it/s, loss=-0.09793]\u001b[A\n",
      "Epoch 2:  23%|████████████▉                                          | 23/98 [00:05<00:16,  4.48it/s, loss=-0.08918]\u001b[A\n",
      "Epoch 2:  24%|█████████████▍                                         | 24/98 [00:05<00:16,  4.48it/s, loss=-0.08918]\u001b[A\n",
      "Epoch 2:  24%|█████████████▍                                         | 24/98 [00:05<00:16,  4.48it/s, loss=-0.10217]\u001b[A\n",
      "Epoch 2:  26%|██████████████                                         | 25/98 [00:05<00:16,  4.52it/s, loss=-0.10217]\u001b[A\n",
      "Epoch 2:  26%|██████████████                                         | 25/98 [00:05<00:16,  4.52it/s, loss=-0.09364]\u001b[A\n",
      "Epoch 2:  27%|██████████████▌                                        | 26/98 [00:06<00:16,  4.49it/s, loss=-0.09364]\u001b[A\n",
      "Epoch 2:  27%|██████████████▌                                        | 26/98 [00:06<00:16,  4.49it/s, loss=-0.09561]\u001b[A\n",
      "Epoch 2:  28%|███████████████▏                                       | 27/98 [00:06<00:15,  4.56it/s, loss=-0.09561]\u001b[A\n",
      "Epoch 2:  28%|███████████████▏                                       | 27/98 [00:06<00:15,  4.56it/s, loss=-0.09924]\u001b[A\n",
      "Epoch 2:  29%|███████████████▋                                       | 28/98 [00:06<00:15,  4.60it/s, loss=-0.09924]\u001b[A\n",
      "Epoch 2:  29%|███████████████▋                                       | 28/98 [00:06<00:15,  4.60it/s, loss=-0.10977]\u001b[A\n",
      "Epoch 2:  30%|████████████████▎                                      | 29/98 [00:06<00:15,  4.49it/s, loss=-0.10977]\u001b[A\n",
      "Epoch 2:  30%|████████████████▎                                      | 29/98 [00:06<00:15,  4.49it/s, loss=-0.11231]\u001b[A\n",
      "Epoch 2:  31%|████████████████▊                                      | 30/98 [00:06<00:15,  4.52it/s, loss=-0.11231]\u001b[A\n",
      "Epoch 2:  31%|████████████████▊                                      | 30/98 [00:06<00:15,  4.52it/s, loss=-0.11787]\u001b[A\n",
      "Epoch 2:  32%|█████████████████▍                                     | 31/98 [00:07<00:14,  4.57it/s, loss=-0.11787]\u001b[A\n",
      "Epoch 2:  32%|█████████████████▍                                     | 31/98 [00:07<00:14,  4.57it/s, loss=-0.12617]\u001b[A\n",
      "Epoch 2:  33%|█████████████████▉                                     | 32/98 [00:07<00:14,  4.52it/s, loss=-0.12617]\u001b[A\n",
      "Epoch 2:  33%|█████████████████▉                                     | 32/98 [00:07<00:14,  4.52it/s, loss=-0.12926]\u001b[A\n",
      "Epoch 2:  34%|██████████████████▌                                    | 33/98 [00:07<00:14,  4.49it/s, loss=-0.12926]\u001b[A\n",
      "Epoch 2:  34%|██████████████████▌                                    | 33/98 [00:07<00:14,  4.49it/s, loss=-0.12908]\u001b[A\n",
      "Epoch 2:  35%|███████████████████                                    | 34/98 [00:07<00:14,  4.38it/s, loss=-0.12908]\u001b[A\n",
      "Epoch 2:  35%|███████████████████                                    | 34/98 [00:07<00:14,  4.38it/s, loss=-0.13267]\u001b[A\n",
      "Epoch 2:  36%|███████████████████▋                                   | 35/98 [00:08<00:14,  4.29it/s, loss=-0.13267]\u001b[A\n",
      "Epoch 2:  36%|███████████████████▋                                   | 35/98 [00:08<00:14,  4.29it/s, loss=-0.13242]\u001b[A\n",
      "Epoch 2:  37%|████████████████████▏                                  | 36/98 [00:08<00:15,  3.99it/s, loss=-0.13242]\u001b[A\n",
      "Epoch 2:  37%|████████████████████▏                                  | 36/98 [00:08<00:15,  3.99it/s, loss=-0.13129]\u001b[A\n",
      "Epoch 2:  38%|████████████████████▊                                  | 37/98 [00:08<00:15,  3.99it/s, loss=-0.13129]\u001b[A\n",
      "Epoch 2:  38%|████████████████████▊                                  | 37/98 [00:08<00:15,  3.99it/s, loss=-0.12823]\u001b[A\n",
      "Epoch 2:  39%|█████████████████████▎                                 | 38/98 [00:08<00:14,  4.11it/s, loss=-0.12823]\u001b[A\n",
      "Epoch 2:  39%|█████████████████████▎                                 | 38/98 [00:08<00:14,  4.11it/s, loss=-0.13091]\u001b[A\n",
      "Epoch 2:  40%|█████████████████████▉                                 | 39/98 [00:09<00:13,  4.26it/s, loss=-0.13091]\u001b[A\n",
      "Epoch 2:  40%|█████████████████████▉                                 | 39/98 [00:09<00:13,  4.26it/s, loss=-0.13714]\u001b[A\n",
      "Epoch 2:  41%|██████████████████████▍                                | 40/98 [00:09<00:13,  4.21it/s, loss=-0.13714]\u001b[A\n",
      "Epoch 2:  41%|██████████████████████▍                                | 40/98 [00:09<00:13,  4.21it/s, loss=-0.13798]\u001b[A\n",
      "Epoch 2:  42%|███████████████████████                                | 41/98 [00:09<00:13,  4.38it/s, loss=-0.13798]\u001b[A\n",
      "Epoch 2:  42%|███████████████████████                                | 41/98 [00:09<00:13,  4.38it/s, loss=-0.13392]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████▌                               | 42/98 [00:09<00:12,  4.37it/s, loss=-0.13392]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████▌                               | 42/98 [00:09<00:12,  4.37it/s, loss=-0.13513]\u001b[A\n",
      "Epoch 2:  44%|████████████████████████▏                              | 43/98 [00:09<00:12,  4.45it/s, loss=-0.13513]\u001b[A\n",
      "Epoch 2:  44%|████████████████████████▏                              | 43/98 [00:09<00:12,  4.45it/s, loss=-0.13500]\u001b[A\n",
      "Epoch 2:  45%|████████████████████████▋                              | 44/98 [00:10<00:12,  4.41it/s, loss=-0.13500]\u001b[A\n",
      "Epoch 2:  45%|████████████████████████▋                              | 44/98 [00:10<00:12,  4.41it/s, loss=-0.13651]\u001b[A\n",
      "Epoch 2:  46%|█████████████████████████▎                             | 45/98 [00:10<00:11,  4.54it/s, loss=-0.13651]\u001b[A\n",
      "Epoch 2:  46%|█████████████████████████▎                             | 45/98 [00:10<00:11,  4.54it/s, loss=-0.13298]\u001b[A\n",
      "Epoch 2:  47%|█████████████████████████▊                             | 46/98 [00:10<00:11,  4.47it/s, loss=-0.13298]\u001b[A\n",
      "Epoch 2:  47%|█████████████████████████▊                             | 46/98 [00:10<00:11,  4.47it/s, loss=-0.13454]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████▍                            | 47/98 [00:10<00:11,  4.43it/s, loss=-0.13454]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████▍                            | 47/98 [00:10<00:11,  4.43it/s, loss=-0.14024]\u001b[A\n",
      "Epoch 2:  49%|██████████████████████████▉                            | 48/98 [00:11<00:11,  4.47it/s, loss=-0.14024]\u001b[A\n",
      "Epoch 2:  49%|██████████████████████████▉                            | 48/98 [00:11<00:11,  4.47it/s, loss=-0.14610]\u001b[A\n",
      "Epoch 2:  50%|███████████████████████████▌                           | 49/98 [00:11<00:11,  4.40it/s, loss=-0.14610]\u001b[A\n",
      "Epoch 2:  50%|███████████████████████████▌                           | 49/98 [00:11<00:11,  4.40it/s, loss=-0.14440]\u001b[A\n",
      "Epoch 2:  51%|████████████████████████████                           | 50/98 [00:11<00:10,  4.45it/s, loss=-0.14440]\u001b[A\n",
      "Epoch 2:  51%|████████████████████████████                           | 50/98 [00:11<00:10,  4.45it/s, loss=-0.14331]\u001b[A\n",
      "Epoch 2:  52%|████████████████████████████▌                          | 51/98 [00:11<00:10,  4.37it/s, loss=-0.14331]\u001b[A\n",
      "Epoch 2:  52%|████████████████████████████▌                          | 51/98 [00:11<00:10,  4.37it/s, loss=-0.14141]\u001b[A\n",
      "Epoch 2:  53%|█████████████████████████████▏                         | 52/98 [00:12<00:10,  4.35it/s, loss=-0.14141]\u001b[A\n",
      "Epoch 2:  53%|█████████████████████████████▏                         | 52/98 [00:12<00:10,  4.35it/s, loss=-0.14470]\u001b[A\n",
      "Epoch 2:  54%|█████████████████████████████▋                         | 53/98 [00:12<00:10,  4.19it/s, loss=-0.14470]\u001b[A\n",
      "Epoch 2:  54%|█████████████████████████████▋                         | 53/98 [00:12<00:10,  4.19it/s, loss=-0.14279]\u001b[A\n",
      "Epoch 2:  55%|██████████████████████████████▎                        | 54/98 [00:12<00:10,  4.32it/s, loss=-0.14279]\u001b[A\n",
      "Epoch 2:  55%|██████████████████████████████▎                        | 54/98 [00:12<00:10,  4.32it/s, loss=-0.14193]\u001b[A\n",
      "Epoch 2:  56%|██████████████████████████████▊                        | 55/98 [00:12<00:10,  4.29it/s, loss=-0.14193]\u001b[A\n",
      "Epoch 2:  56%|██████████████████████████████▊                        | 55/98 [00:12<00:10,  4.29it/s, loss=-0.14337]\u001b[A\n",
      "Epoch 2:  57%|███████████████████████████████▍                       | 56/98 [00:12<00:09,  4.41it/s, loss=-0.14337]\u001b[A\n",
      "Epoch 2:  57%|███████████████████████████████▍                       | 56/98 [00:12<00:09,  4.41it/s, loss=-0.14504]\u001b[A\n",
      "Epoch 2:  58%|███████████████████████████████▉                       | 57/98 [00:13<00:09,  4.39it/s, loss=-0.14504]\u001b[A\n",
      "Epoch 2:  58%|███████████████████████████████▉                       | 57/98 [00:13<00:09,  4.39it/s, loss=-0.14379]\u001b[A\n",
      "Epoch 2:  59%|████████████████████████████████▌                      | 58/98 [00:13<00:10,  3.96it/s, loss=-0.14379]\u001b[A\n",
      "Epoch 2:  59%|████████████████████████████████▌                      | 58/98 [00:13<00:10,  3.96it/s, loss=-0.14511]\u001b[A\n",
      "Epoch 2:  60%|█████████████████████████████████                      | 59/98 [00:13<00:10,  3.63it/s, loss=-0.14511]\u001b[A\n",
      "Epoch 2:  60%|█████████████████████████████████                      | 59/98 [00:13<00:10,  3.63it/s, loss=-0.14526]\u001b[A\n",
      "Epoch 2:  61%|█████████████████████████████████▋                     | 60/98 [00:14<00:10,  3.60it/s, loss=-0.14526]\u001b[A\n",
      "Epoch 2:  61%|█████████████████████████████████▋                     | 60/98 [00:14<00:10,  3.60it/s, loss=-0.14664]\u001b[A\n",
      "Epoch 2:  62%|██████████████████████████████████▏                    | 61/98 [00:14<00:10,  3.67it/s, loss=-0.14664]\u001b[A\n",
      "Epoch 2:  62%|██████████████████████████████████▏                    | 61/98 [00:14<00:10,  3.67it/s, loss=-0.14385]\u001b[A\n",
      "Epoch 2:  63%|██████████████████████████████████▊                    | 62/98 [00:14<00:09,  3.84it/s, loss=-0.14385]\u001b[A\n",
      "Epoch 2:  63%|██████████████████████████████████▊                    | 62/98 [00:14<00:09,  3.84it/s, loss=-0.14385]\u001b[A\n",
      "Epoch 2:  64%|███████████████████████████████████▎                   | 63/98 [00:14<00:08,  3.94it/s, loss=-0.14385]\u001b[A\n",
      "Epoch 2:  64%|███████████████████████████████████▎                   | 63/98 [00:14<00:08,  3.94it/s, loss=-0.14362]\u001b[A\n",
      "Epoch 2:  65%|███████████████████████████████████▉                   | 64/98 [00:15<00:08,  4.04it/s, loss=-0.14362]\u001b[A\n",
      "Epoch 2:  65%|███████████████████████████████████▉                   | 64/98 [00:15<00:08,  4.04it/s, loss=-0.14257]\u001b[A\n",
      "Epoch 2:  66%|████████████████████████████████████▍                  | 65/98 [00:15<00:07,  4.13it/s, loss=-0.14257]\u001b[A\n",
      "Epoch 2:  66%|████████████████████████████████████▍                  | 65/98 [00:15<00:07,  4.13it/s, loss=-0.14045]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████████████████████                  | 66/98 [00:15<00:07,  4.26it/s, loss=-0.14045]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████████████████████                  | 66/98 [00:15<00:07,  4.26it/s, loss=-0.13857]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████████████████████▌                 | 67/98 [00:15<00:07,  4.31it/s, loss=-0.13857]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████████████████████▌                 | 67/98 [00:15<00:07,  4.31it/s, loss=-0.13769]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████████████████████▏                | 68/98 [00:15<00:07,  4.25it/s, loss=-0.13769]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████████████████████▏                | 68/98 [00:15<00:07,  4.25it/s, loss=-0.13802]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████▋                | 69/98 [00:16<00:06,  4.22it/s, loss=-0.13802]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████▋                | 69/98 [00:16<00:06,  4.22it/s, loss=-0.13716]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████████▎               | 70/98 [00:16<00:06,  4.30it/s, loss=-0.13716]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████████▎               | 70/98 [00:16<00:06,  4.30it/s, loss=-0.13186]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████████▊               | 71/98 [00:16<00:06,  4.21it/s, loss=-0.13186]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████████▊               | 71/98 [00:16<00:06,  4.21it/s, loss=-0.13760]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████████▍              | 72/98 [00:16<00:06,  4.14it/s, loss=-0.13760]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████████▍              | 72/98 [00:16<00:06,  4.14it/s, loss=-0.13788]\u001b[A\n",
      "Epoch 2:  74%|████████████████████████████████████████▉              | 73/98 [00:17<00:06,  4.12it/s, loss=-0.13788]\u001b[A\n",
      "Epoch 2:  74%|████████████████████████████████████████▉              | 73/98 [00:17<00:06,  4.12it/s, loss=-0.13986]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████████████████████▌             | 74/98 [00:17<00:06,  4.00it/s, loss=-0.13986]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████████████████████▌             | 74/98 [00:17<00:06,  4.00it/s, loss=-0.14121]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████████             | 75/98 [00:17<00:05,  3.90it/s, loss=-0.14121]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████████             | 75/98 [00:17<00:05,  3.90it/s, loss=-0.13993]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████████████████████▋            | 76/98 [00:17<00:05,  3.84it/s, loss=-0.13993]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████████████████████▋            | 76/98 [00:17<00:05,  3.84it/s, loss=-0.13821]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████████▏           | 77/98 [00:18<00:05,  3.92it/s, loss=-0.13821]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████████▏           | 77/98 [00:18<00:05,  3.92it/s, loss=-0.13886]\u001b[A\n",
      "Epoch 2:  80%|███████████████████████████████████████████▊           | 78/98 [00:18<00:04,  4.07it/s, loss=-0.13886]\u001b[A\n",
      "Epoch 2:  80%|███████████████████████████████████████████▊           | 78/98 [00:18<00:04,  4.07it/s, loss=-0.14134]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████████▎          | 79/98 [00:18<00:04,  4.02it/s, loss=-0.14134]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████████▎          | 79/98 [00:18<00:04,  4.02it/s, loss=-0.14131]\u001b[A\n",
      "Epoch 2:  82%|████████████████████████████████████████████▉          | 80/98 [00:18<00:04,  4.15it/s, loss=-0.14131]\u001b[A\n",
      "Epoch 2:  82%|████████████████████████████████████████████▉          | 80/98 [00:18<00:04,  4.15it/s, loss=-0.14323]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████████▍         | 81/98 [00:19<00:04,  4.19it/s, loss=-0.14323]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████████▍         | 81/98 [00:19<00:04,  4.19it/s, loss=-0.14265]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████████         | 82/98 [00:19<00:03,  4.32it/s, loss=-0.14265]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████████         | 82/98 [00:19<00:03,  4.32it/s, loss=-0.14406]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████████▌        | 83/98 [00:19<00:03,  4.33it/s, loss=-0.14406]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████████▌        | 83/98 [00:19<00:03,  4.33it/s, loss=-0.14483]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████████████████████████▏       | 84/98 [00:19<00:03,  4.40it/s, loss=-0.14483]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████████████████████████▏       | 84/98 [00:19<00:03,  4.40it/s, loss=-0.14388]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████████▋       | 85/98 [00:20<00:02,  4.35it/s, loss=-0.14388]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████████▋       | 85/98 [00:20<00:02,  4.35it/s, loss=-0.14469]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████████▎      | 86/98 [00:20<00:02,  4.40it/s, loss=-0.14469]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████████▎      | 86/98 [00:20<00:02,  4.40it/s, loss=-0.14478]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████████▊      | 87/98 [00:20<00:02,  4.40it/s, loss=-0.14478]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████████▊      | 87/98 [00:20<00:02,  4.40it/s, loss=-0.14352]\u001b[A\n",
      "Epoch 2:  90%|█████████████████████████████████████████████████▍     | 88/98 [00:20<00:02,  4.47it/s, loss=-0.14352]\u001b[A\n",
      "Epoch 2:  90%|█████████████████████████████████████████████████▍     | 88/98 [00:20<00:02,  4.47it/s, loss=-0.14336]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████▉     | 89/98 [00:20<00:02,  4.42it/s, loss=-0.14336]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████▉     | 89/98 [00:20<00:02,  4.42it/s, loss=-0.14345]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████████▌    | 90/98 [00:21<00:01,  4.48it/s, loss=-0.14345]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████████▌    | 90/98 [00:21<00:01,  4.48it/s, loss=-0.14442]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████████    | 91/98 [00:21<00:01,  4.43it/s, loss=-0.14442]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████████    | 91/98 [00:21<00:01,  4.43it/s, loss=-0.14127]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████████▋   | 92/98 [00:21<00:01,  4.41it/s, loss=-0.14127]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████████▋   | 92/98 [00:21<00:01,  4.41it/s, loss=-0.14035]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████████▏  | 93/98 [00:21<00:01,  4.41it/s, loss=-0.14035]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████████▏  | 93/98 [00:21<00:01,  4.41it/s, loss=-0.14009]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████████▊  | 94/98 [00:22<00:00,  4.37it/s, loss=-0.14009]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████████▊  | 94/98 [00:22<00:00,  4.37it/s, loss=-0.14311]\u001b[A\n",
      "Epoch 2:  97%|█████████████████████████████████████████████████████▎ | 95/98 [00:22<00:00,  4.42it/s, loss=-0.14311]\u001b[A\n",
      "Epoch 2:  97%|█████████████████████████████████████████████████████▎ | 95/98 [00:22<00:00,  4.42it/s, loss=-0.14571]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████████████████████████▉ | 96/98 [00:22<00:00,  4.37it/s, loss=-0.14571]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████████████████████████▉ | 96/98 [00:22<00:00,  4.37it/s, loss=-0.14458]\u001b[A\n",
      "Epoch 2:  99%|██████████████████████████████████████████████████████▍| 97/98 [00:22<00:00,  4.45it/s, loss=-0.14458]\u001b[A\n",
      "Epoch 2:  99%|██████████████████████████████████████████████████████▍| 97/98 [00:22<00:00,  4.45it/s, loss=-0.14599]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████████| 98/98 [00:22<00:00,  4.45it/s, loss=-0.14723]\u001b[A\n",
      "Epoch 2: 100%|██████████████| 98/98 [00:37<00:00,  4.45it/s, loss=-0.14723, test_loss=-0.12669, train_loss=-0.17991]\u001b[A\n",
      "Epoch 2: 100%|██████████████| 98/98 [00:37<00:00,  2.60it/s, loss=-0.14723, test_loss=-0.12669, train_loss=-0.17991]\u001b[A\n",
      "Epoch 3:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 3: 100%|██████████████| 98/98 [00:35<00:00,  2.78it/s, loss=-0.17857, test_loss=-0.14346, train_loss=-0.20961]\n",
      "Epoch 4:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 4: 100%|██████████████| 98/98 [00:35<00:00,  2.73it/s, loss=-0.20670, test_loss=-0.14248, train_loss=-0.23543]\n",
      "Epoch 5:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 5: 100%|██████████████| 98/98 [00:35<00:00,  2.73it/s, loss=-0.23816, test_loss=-0.17636, train_loss=-0.25934]\n",
      "Epoch 6:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 6: 100%|██████████████| 98/98 [00:37<00:00,  2.64it/s, loss=-0.27180, test_loss=-0.16451, train_loss=-0.27365]\n",
      "Epoch 7:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 7: 100%|██████████████| 98/98 [00:35<00:00,  2.75it/s, loss=-0.28959, test_loss=-0.18022, train_loss=-0.30318]\n",
      "Epoch 8:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 8: 100%|██████████████| 98/98 [00:35<00:00,  2.76it/s, loss=-0.31536, test_loss=-0.17049, train_loss=-0.31268]\n",
      "Epoch 9:   0%|                                                                               | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 9: 100%|██████████████| 98/98 [00:35<00:00,  2.78it/s, loss=-0.32768, test_loss=-0.18854, train_loss=-0.32975]\n",
      "Epoch 10:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 10: 100%|█████████████| 98/98 [00:35<00:00,  2.79it/s, loss=-0.35047, test_loss=-0.18712, train_loss=-0.34201]\n",
      "Epoch 11:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 11: 100%|█████████████| 98/98 [00:35<00:00,  2.75it/s, loss=-0.36208, test_loss=-0.20330, train_loss=-0.35154]\n",
      "Epoch 12:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 12: 100%|█████████████| 98/98 [00:35<00:00,  2.76it/s, loss=-0.38018, test_loss=-0.21381, train_loss=-0.36978]\n",
      "Epoch 13:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 13: 100%|█████████████| 98/98 [00:35<00:00,  2.74it/s, loss=-0.40061, test_loss=-0.22125, train_loss=-0.36511]\n",
      "Epoch 14:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 14: 100%|█████████████| 98/98 [00:34<00:00,  2.82it/s, loss=-0.41220, test_loss=-0.21815, train_loss=-0.37209]\n",
      "Epoch 15:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 15: 100%|█████████████| 98/98 [00:36<00:00,  2.65it/s, loss=-0.41989, test_loss=-0.23241, train_loss=-0.38334]\n",
      "Epoch 16:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 16: 100%|█████████████| 98/98 [00:40<00:00,  2.43it/s, loss=-0.42889, test_loss=-0.23015, train_loss=-0.40219]\n",
      "Epoch 17:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 17: 100%|█████████████| 98/98 [00:37<00:00,  2.64it/s, loss=-0.45401, test_loss=-0.24413, train_loss=-0.40369]\n",
      "Epoch 18:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 18: 100%|█████████████| 98/98 [00:37<00:00,  2.62it/s, loss=-0.45375, test_loss=-0.24315, train_loss=-0.41400]\n",
      "Epoch 19:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 19: 100%|█████████████| 98/98 [00:35<00:00,  2.73it/s, loss=-0.46977, test_loss=-0.23474, train_loss=-0.42391]\n",
      "Epoch 20:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 20: 100%|█████████████| 98/98 [00:35<00:00,  2.80it/s, loss=-0.47417, test_loss=-0.26199, train_loss=-0.42932]\n",
      "Epoch 21:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 21: 100%|█████████████| 98/98 [00:35<00:00,  2.77it/s, loss=-0.49900, test_loss=-0.26853, train_loss=-0.43707]\n",
      "Epoch 22:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 22: 100%|█████████████| 98/98 [00:35<00:00,  2.78it/s, loss=-0.49671, test_loss=-0.27448, train_loss=-0.44263]\n",
      "Epoch 23:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 23: 100%|█████████████| 98/98 [00:35<00:00,  2.77it/s, loss=-0.49523, test_loss=-0.28277, train_loss=-0.45320]\n",
      "Epoch 24:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 24: 100%|█████████████| 98/98 [00:36<00:00,  2.72it/s, loss=-0.51432, test_loss=-0.27973, train_loss=-0.45717]\n",
      "Epoch 25:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 25: 100%|█████████████| 98/98 [00:37<00:00,  2.60it/s, loss=-0.52458, test_loss=-0.26674, train_loss=-0.46910]\n",
      "Epoch 26:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 26: 100%|█████████████| 98/98 [00:37<00:00,  2.64it/s, loss=-0.54861, test_loss=-0.27186, train_loss=-0.47183]\n",
      "Epoch 27:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 27: 100%|█████████████| 98/98 [00:36<00:00,  2.66it/s, loss=-0.54245, test_loss=-0.28197, train_loss=-0.47909]\n",
      "Epoch 28:   0%|                                                                              | 0/98 [00:00<?, ?it/s]C:\\Program Files\\Anaconda3\\envs\\py38\\lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 28: 100%|█████████████| 98/98 [00:37<00:00,  2.63it/s, loss=-0.55360, test_loss=-0.28037, train_loss=-0.48455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training interrupted\n",
      "Training stopped early because there was no improvement in test_loss for 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.53436, test_loss=-0.24826, train_loss=-0.44829]\n",
      "Epoch 33:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 33: 100%|████████████████| 98/98 [01:11<00:00,  1.38it/s, loss=-0.52777, test_loss=-0.26234, train_loss=-0.45614]\n",
      "Epoch 34:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 34: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.55608, test_loss=-0.25195, train_loss=-0.45860]\n",
      "Epoch 35:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 35: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.55736, test_loss=-0.27271, train_loss=-0.46641]\n",
      "Epoch 36:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 36: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.55732, test_loss=-0.25654, train_loss=-0.46648]\n",
      "Epoch 37:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 37: 100%|████████████████| 98/98 [01:11<00:00,  1.38it/s, loss=-0.56527, test_loss=-0.25956, train_loss=-0.47182]\n",
      "Epoch 38:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 38: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.56540, test_loss=-0.27265, train_loss=-0.47126]\n",
      "Epoch 39:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 39: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.57418, test_loss=-0.26327, train_loss=-0.47271]\n",
      "Epoch 40:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 40: 100%|████████████████| 98/98 [01:11<00:00,  1.38it/s, loss=-0.58231, test_loss=-0.27564, train_loss=-0.47800]\n",
      "Epoch 41:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 41: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.59258, test_loss=-0.27274, train_loss=-0.48073]\n",
      "Epoch 42:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 42: 100%|████████████████| 98/98 [01:11<00:00,  1.38it/s, loss=-0.59369, test_loss=-0.27056, train_loss=-0.48211]\n",
      "Epoch 43:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.59911, test_loss=-0.26833, train_loss=-0.48062]\n",
      "Epoch 44:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 44: 100%|████████████████| 98/98 [01:11<00:00,  1.38it/s, loss=-0.60319, test_loss=-0.26319, train_loss=-0.48262]\n",
      "Epoch 45:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 45: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.59897, test_loss=-0.25654, train_loss=-0.48750]\n",
      "Epoch 46:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 46: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.60781, test_loss=-0.25630, train_loss=-0.48488]\n",
      "Epoch 47:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 47: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.59884, test_loss=-0.27224, train_loss=-0.49354]\n",
      "Epoch 48:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 48: 100%|████████████████| 98/98 [01:12<00:00,  1.35it/s, loss=-0.60224, test_loss=-0.26645, train_loss=-0.49646]\n",
      "Epoch 49:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 49: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.60809, test_loss=-0.27868, train_loss=-0.50566]\n",
      "Epoch 50:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 50: 100%|████████████████| 98/98 [01:12<00:00,  1.35it/s, loss=-0.61800, test_loss=-0.29405, train_loss=-0.50716]\n",
      "Epoch 51:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 51: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.62366, test_loss=-0.28039, train_loss=-0.51191]\n",
      "Epoch 52:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 52: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.63273, test_loss=-0.27510, train_loss=-0.50921]\n",
      "Epoch 53:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 53: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.61402, test_loss=-0.28099, train_loss=-0.51198]\n",
      "Epoch 54:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|████████████████| 98/98 [01:12<00:00,  1.35it/s, loss=-0.63999, test_loss=-0.28442, train_loss=-0.51104]\n",
      "Epoch 55:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 55: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.64263, test_loss=-0.27984, train_loss=-0.51408]\n",
      "Epoch 56:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 56: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.63992, test_loss=-0.27070, train_loss=-0.51599]\n",
      "Epoch 57:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 57: 100%|████████████████| 98/98 [01:37<00:00,  1.01it/s, loss=-0.64435, test_loss=-0.28304, train_loss=-0.51091]\n",
      "Epoch 58:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 58: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.64984, test_loss=-0.28570, train_loss=-0.52123]\n",
      "Epoch 59:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 59: 100%|████████████████| 98/98 [01:11<00:00,  1.38it/s, loss=-0.65279, test_loss=-0.29200, train_loss=-0.51949]\n",
      "Epoch 60:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 60: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.64951, test_loss=-0.29756, train_loss=-0.52558]\n",
      "Epoch 61:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 61: 100%|████████████████| 98/98 [01:33<00:00,  1.04it/s, loss=-0.66503, test_loss=-0.29111, train_loss=-0.52625]\n",
      "Epoch 62:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 62: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.66067, test_loss=-0.29926, train_loss=-0.53258]\n",
      "Epoch 63:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 63: 100%|████████████████| 98/98 [01:11<00:00,  1.37it/s, loss=-0.64978, test_loss=-0.30665, train_loss=-0.53912]\n",
      "Epoch 64:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 64: 100%|████████████████| 98/98 [01:34<00:00,  1.04it/s, loss=-0.66587, test_loss=-0.30595, train_loss=-0.53546]\n",
      "Epoch 65:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|████████████████| 98/98 [01:11<00:00,  1.36it/s, loss=-0.69093, test_loss=-0.31174, train_loss=-0.53299]\n",
      "Epoch 66:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 66: 100%|████████████████| 98/98 [01:12<00:00,  1.36it/s, loss=-0.65226, test_loss=-0.29525, train_loss=-0.54031]\n",
      "Epoch 67:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 67: 100%|████████████████| 98/98 [01:31<00:00,  1.07it/s, loss=-0.67756, test_loss=-0.30939, train_loss=-0.54309]\n",
      "Epoch 68:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 68: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.67460, test_loss=-0.31728, train_loss=-0.54637]\n",
      "Epoch 69:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 69: 100%|████████████████| 98/98 [01:33<00:00,  1.05it/s, loss=-0.68930, test_loss=-0.32991, train_loss=-0.54052]\n",
      "Epoch 70:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 70: 100%|████████████████| 98/98 [01:10<00:00,  1.39it/s, loss=-0.67229, test_loss=-0.32735, train_loss=-0.54585]\n",
      "Epoch 71:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 71: 100%|████████████████| 98/98 [01:31<00:00,  1.07it/s, loss=-0.68789, test_loss=-0.31571, train_loss=-0.54919]\n",
      "Epoch 72:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 72: 100%|████████████████| 98/98 [01:10<00:00,  1.38it/s, loss=-0.69089, test_loss=-0.31569, train_loss=-0.55267]\n",
      "Epoch 73:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 73: 100%|████████████████| 98/98 [01:33<00:00,  1.04it/s, loss=-0.67781, test_loss=-0.32609, train_loss=-0.55026]\n",
      "Epoch 74:   0%|                                                                                 | 0/98 [00:00<?, ?it/s]C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Epoch 74:  10%|█████▊                                                   | 10/98 [00:04<00:41,  2.14it/s, loss=-0.48615]"
     ]
    }
   ],
   "source": [
    "history = run.launch(450)\n",
    "torch.save(network.state_dict(), 'network_2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1ZAJiA3WIb8"
   },
   "source": [
    "# Check model perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_C6qYeh57N2",
    "outputId": "d7e4d6ec-0ea7-4cd8-85a1-db313452e03c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Exception ignored in: <function tqdm.__del__ at 0x00000280484739D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\tqdm\\std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\tqdm\\std.py\", line 1268, in close\n",
      "    if self.disable:\n",
      "AttributeError: 'tqdm' object has no attribute 'disable'\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # network = LstmNetMinVar(5)\n",
    "  # network.load_state_dict(torch.load(fr'network_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5V7kXiXFfA29"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m per_epoch_results \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "per_epoch_results = history.metrics.groupby(['dataloader', 'metric', 'model', 'epoch'])['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "e8UrNSPoTV4w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "A5Dtu_QyeIrf",
    "outputId": "04d75fd0-5a81-4d6f-9546-967462c18605"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_test_loss = per_epoch_results.mean()['test']['loss']['network'] # tmp\n",
    "\n",
    "# Plotting the mean test loss per epoch\n",
    "mean_test_loss.plot()\n",
    "\n",
    "# Finding the epoch with the minimum test loss\n",
    "min_loss_epoch = mean_test_loss.idxmin()\n",
    "min_loss_value = mean_test_loss.min()\n",
    "\n",
    "# Adding a red vertical line at the epoch with minimum test loss\n",
    "plt.axvline(x=min_loss_epoch, color='r', linestyle='--', label=f'Min Loss at Epoch {min_loss_epoch}')\n",
    "\n",
    "# Adding some labels and title for clarity\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNjFRuqyp9R3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9tBNUrqa4qO",
    "outputId": "a4f5a9e3-da2c-4207-eee3-202084d6e215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6797077"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_epoch_results.mean()['test']['loss']['network'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "on_gcl3zWx5p",
    "outputId": "18189bc7-f1ca-4fbc-ce19-cd5087369c35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_train_loss = per_epoch_results.mean()['train']['loss']['network']\n",
    "\n",
    "# Plotting the mean test loss per epoch\n",
    "mean_train_loss.plot()\n",
    "\n",
    "\n",
    "\n",
    "# Adding some labels and title for clarity\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.title('Train Loss per Epoch')\n",
    "plt.axvline(x=min_loss_epoch, color='r', linestyle='--', label=f'The best model {min_loss_epoch}')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "pJDxvq5hPuml"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from deepdowmine.benchmarks import Benchmark, OneOverN, Random\n",
    "\n",
    "benchmarks = {\n",
    "    '1overN': OneOverN(),  # each asset has weight 1 / n_assets\n",
    "    'network': network\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    'Sharpe': SharpeRatio(),\n",
    "}\n",
    "\n",
    "\n",
    "metrics_table = generate_metrics_table(benchmarks,\n",
    "                                       dataloader_test,\n",
    "                                       metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4vNvSxtQVuj",
    "outputId": "b0c40c6c-2352-418b-b1e7-5147809bcd21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.66514"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table[metrics_table['benchmark'] == 'network']['value'].mean() / metrics_table[metrics_table['benchmark'] == '1overN']['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zQ7QsvJairmN",
    "outputId": "cc860057-9bb5-4b39-a085-327a9837ab3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.056892693"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table[metrics_table['benchmark'] == '1overN']['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "s6rRvv1eS7kj",
    "outputId": "38f3b0b8-be12-472c-b627-c0973379e41c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01617861"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table[metrics_table['benchmark'] == 'network']['value'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua5Bfj50VeN0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IJuWjQ14WnlV",
    "outputId": "378e7498-829e-4989-f6e0-6489756743b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "i7oRCao6Vfj0"
   },
   "outputs": [],
   "source": [
    "one_over_n = metrics_table[metrics_table['benchmark'] == '1overN']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KPzn5AonWaC7",
    "outputId": "ca1934e1-9831-46de-8c12-f409297effb6"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3111 is out of bounds for axis 0 with size 346",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ef515d04ffdd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_over_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 3111 is out of bounds for axis 0 with size 346"
     ]
    }
   ],
   "source": [
    "np.array(one_over_n)[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fgUtZqOsUmXW"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the two conditions\n",
    "one_over_n = -metrics_table[metrics_table['benchmark'] == '1overN']['value']\n",
    "network_res = -metrics_table[metrics_table['benchmark'] == 'network']['value']\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(one_over_n))  # This will create an array [0, 1, ..., n-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each series on the same plot\n",
    "plt.plot(x_axis, one_over_n, label='1overN', marker='o', linestyle='-')\n",
    "plt.plot(x_axis, network_res, label='Network', marker='x', linestyle='-')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Sharpe Ratio Comparison')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "z8OafQ7sks66",
    "outputId": "f2d25704-bec3-4a2b-a7b1-8daa75a1e096"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f97c1788b27d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'network_res' is not defined"
     ]
    }
   ],
   "source": [
    "network_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hZrjG1lcQobW"
   },
   "outputs": [],
   "source": [
    "metrics_table[metrics_table['benchmark'] == 'network']['value'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5eJGUoOGQbx"
   },
   "source": [
    "# Load the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYwpyZGaDw08"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LjHeQ5pDviF"
   },
   "outputs": [],
   "source": [
    "network = LinearNetMine(1, lookback, n_assets, p=0.5)\n",
    "network.load_state_dict(torch.load('linear_net_50x5_sharpe.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33X2Kz5wPqQo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flRu6fv_7iHV"
   },
   "source": [
    "# Supplementary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hwj73IJws4sh"
   },
   "outputs": [],
   "source": [
    "# 1.363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkdrpOm10PR7"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_zN5p6hwjbx"
   },
   "outputs": [],
   "source": [
    "test_X = torch.tensor(X[[-1]], dtype=torch.float32)#(X[indices_train], dtype=torch.float32) #indices_train\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GLpaetmxY1j"
   },
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    # This function will return a hook function that stores the output in a dictionary\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Attach the hook to the covariance_layer, which precedes the channel_collapse_layer\n",
    "activations = {}\n",
    "hook = network.portfolio_opt_layer.register_forward_hook(get_activation('portfolio_opt_layer'))\n",
    "\n",
    "# Now run your data through the network. This will store the output of the covariance_layer in activations\n",
    "network(test_X)\n",
    "\n",
    "# The output you're interested in is now stored in activations['covariance_layer_output']\n",
    "input_to_channel_collapse = activations['portfolio_opt_layer']\n",
    "\n",
    "# Don't forget to remove the hook when you're done to prevent memory leaks\n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zplSbU-wxa_b"
   },
   "outputs": [],
   "source": [
    "input_to_channel_collapse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJUiUbyqyNKx"
   },
   "outputs": [],
   "source": [
    "network(test_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FY1f1XULzwxF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BlApRJuPfrxq",
    "VNqxm-tdcv3Y",
    "P5eJGUoOGQbx"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
