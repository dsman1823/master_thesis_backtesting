{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a388c7d0",
   "metadata": {},
   "source": [
    "# This notebook provides portfolio weights based on the historical data to the backtesting notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a4ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall deepdowmine\n",
    "#!pip install git+https://github.com/dsman1823/deepdowmine.git\n",
    "#!conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch # <---- to Enable SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b37e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime \n",
    "from deepdowmine.nn import LinearNetMine, UpdNumericalMarkowitzWithShorting, UpdLinearNetMine, UpdDenseNet, UpdUpdLinearNetMine\n",
    "from deepdowmine.nn import DenseNetMinVar, ConvNetFullOpti, ConvNetMinVar, RnnNetMinVar, LstmNetMinVar, RnnNetFullOpti\n",
    "from deepdowmine.nn import LstmNetFullOpti, DenseNetFullOpti2, DenseNetMinVar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fd3bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETS_FILE_PATH = 'historical_returns.csv'\n",
    "\n",
    "\n",
    "\n",
    "loockback, gap, horizon = 50, 0, 5\n",
    "n_assets = 5\n",
    "loockback = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88f90a",
   "metadata": {},
   "source": [
    "## Load NN from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a91bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINEAR_NET_OSHARPE_FILE_PATH = r'./NNs/linear_net_50x5_sharpe.pth' # LinearNetMine with ordinary Sharpe cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a634b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years parameter reprsenets amount of years after the backtest stasrt: the model dowloaded is the the model trained \n",
    "# on the period (train_start, back_test_start + years) \n",
    "\n",
    "\n",
    "# LinearNetMine with ordinary sharpe cost function\n",
    "def load_linear_net_osharpe(years=0):\n",
    "    network = LinearNetMine(1, loockback, n_assets, p=0.5)\n",
    "    network.load_state_dict(torch.load(fr'./NNs/linear_net_50x5_sharpe_{years}.pth'))\n",
    "    print(fr'./NNs/linear_net_50x5_sharpe_{years}.pth')\n",
    "    return network.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd38307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dense_net(years=0):\n",
    "    network = UpdLinearNetMine(1, loockback, n_assets, p=0.5)\n",
    "    network.load_state_dict(torch.load(fr'./NNs/dense_{years}.pth'))\n",
    "    print(fr'dense_{years}.pth')\n",
    "    return network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6d5c7",
   "metadata": {},
   "source": [
    "## Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0ed9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_rets_to_NN_input(rets):\n",
    "    # tranform (loockback, n_assets) df into (1, 1, loockback, n_assets)=(sample_size, n_channels, loockback, n_assets) tensor \n",
    "    returns_np = rets.to_numpy()\n",
    "\n",
    "    # Add the required dimensions: (n_samples, n_channels, lookback, n_assets)\n",
    "    returns_np_expanded = np.expand_dims(returns_np, axis=0)  # Adds n_samples dimension\n",
    "    returns_np_expanded = np.expand_dims(returns_np_expanded, axis=0)  \n",
    "    return torch.from_numpy(returns_np_expanded).float()\n",
    "\n",
    "def weights_from_NN(rets, network):\n",
    "    X = transform_rets_to_NN_input(rets)\n",
    "    return network(X).detach().numpy()[0]\n",
    "\n",
    "# method is a function, used for obtaining the returns\n",
    "def get_weights(method):\n",
    "    rets = pd.read_csv(RETS_FILE_PATH, index_col=0)\n",
    "    return method(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21a7d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06418574,  0.25817055, -0.01574563,  0.60880786,  0.08458146],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets = pd.read_csv(RETS_FILE_PATH, index_col=0)\n",
    "X = transform_rets_to_NN_input(rets)\n",
    "network = LinearNetMine(1, loockback, n_assets, p=0.5)\n",
    "network.load_state_dict(torch.load(fr'./NNs/linear_net_50x5_sharpe_{2}.pth'))\n",
    "network.eval()(X).detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65c2c4",
   "metadata": {},
   "source": [
    "## NNs and related methods\n",
    "\n",
    "\n",
    "### NNs\n",
    "\n",
    "networks[i] method is trained on (train_start, backtest_start + i years) data interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ac6576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./NNs/linear_net_50x5_sharpe_0.pth\n",
      "./NNs/linear_net_50x5_sharpe_1.pth\n",
      "./NNs/linear_net_50x5_sharpe_2.pth\n",
      "dense_0.pth\n",
      "dense_1.pth\n",
      "dense_2.pth\n"
     ]
    }
   ],
   "source": [
    "years = [0, 1, 2]#, 1, 2]\n",
    "\n",
    "linear_osharpe_networks = [load_linear_net_osharpe(years=i) for i in years]\n",
    "dense_networks = [load_dense_net(years=i) for i in years]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b112d",
   "metadata": {},
   "source": [
    "### methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "728b35c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0484,  0.0029, -0.0442], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_networks[1].linear0.bias[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35739537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0484,  0.0029, -0.0442], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_networks[2].linear0.bias[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28670905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the format of lambda \n",
    "linear_osharpe_methods = [lambda r, i=i: weights_from_NN(r, linear_osharpe_networks[i]) for i in years] \n",
    "dense_methods = [lambda r, i=i: weights_from_NN(r, dense_networks[i]) for i in years] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7045f79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.01819081, 0.24908274, 0.29753768, 0.41258937, 0.0225994 ],\n",
       "       dtype=float32),\n",
       " array([-0.03791929,  0.1064674 ,  0.4017897 ,  0.46670547,  0.06295667],\n",
       "       dtype=float32),\n",
       " array([-0.03175861,  0.18791872,  0.14897145,  0.48070765,  0.21416074],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_weights(dense_methods[i]) for i in years]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fae4ce",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be630bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, date\n",
    "\n",
    "RETRAINING_DATE1 = date(2018, 12, 15)\n",
    "RETRAINING_DATE2 = date(2019, 12, 15)\n",
    "\n",
    "# RETRAINING_DATE1 = date(2021, 12, 15)\n",
    "# RETRAINING_DATE2 = date(2022, 12, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3132195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdowmine.nn import DenseNetFullOpti, ConvNetMinVar, DenseNetFullOpti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62cc3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for your Flask app\n",
    "\n",
    "markers = {}\n",
    "markers['net_initialized'] = False\n",
    "\n",
    "@app.route('/get_weights', methods=['GET'])\n",
    "def get_request():\n",
    "    # Extract date string from the query parameters\n",
    "    date_str = request.args.get('date', None)\n",
    "    \n",
    "    # Simple validation to check if date is provided\n",
    "    if not date_str:\n",
    "        return jsonify({\"error\": \"Missing date parameter\"}), 400\n",
    "\n",
    "    # Try to convert the date string to a datetime object\n",
    "    try:\n",
    "        # Note that now we're only parsing the date, not the time\n",
    "        date = datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "    except ValueError:\n",
    "        # If there is an error in parsing the date, return an error message\n",
    "        return jsonify({\"error\": \"Invalid date format. Please use YYYY-MM-DD format.\"}), 400\n",
    "    \n",
    "    years_plus = 0\n",
    "    network = DenseNetMinVar2(1, 50, 5,  max_weight=1, p=0.2)\n",
    "    network.load_state_dict(torch.load(fr'./NNs/trained_on_old_data/dense/min_var_0.pth'))\n",
    "\n",
    "    \n",
    "    if date < RETRAINING_DATE1:\n",
    "        print(0)\n",
    "    if RETRAINING_DATE1 < date < RETRAINING_DATE2:\n",
    "        print('1')\n",
    "        network = DenseNetMinVar2(1, 50, 5,  max_weight=1, p=0.2)\n",
    "        network.load_state_dict(torch.load(fr'./NNs/trained_on_old_data/dense/min_var_1.pth'))\n",
    "    if RETRAINING_DATE2 < date:\n",
    "        print('2')\n",
    "        network = DenseNetMinVar2(1, 50, 5,  max_weight=1, p=0.2)\n",
    "        network.load_state_dict(torch.load(fr'./NNs/trained_on_old_data/dense/min_var_2.pth'))\n",
    "\n",
    "#     network = DenseNetMinVar2(1, 50, 5,  max_weight=1, p=0.2)\n",
    "#     network.load_state_dict(torch.load(fr'./NNs/trained_on_old_data/dense/min_var_0.pth'))\n",
    "      \n",
    "#     if date < RETRAINING_DATE1:\n",
    "#         print(0)\n",
    "#     if RETRAINING_DATE1 < date < RETRAINING_DATE2:\n",
    "#         print('1')\n",
    "#         network = DenseNetMinVar2(1, 50, 5,  max_weight=1, p=0.2)\n",
    "#         network.load_state_dict(torch.load(fr'./NNs/trained_on_old_data/dense/N/min_var_0.pth'))\n",
    "    \n",
    "#     if RETRAINING_DATE2 < date:\n",
    "#         network = DenseNetMinVar2(1, 50, 5,  max_weight=1, p=0.2)\n",
    "#         network.load_state_dict(torch.load(fr'./NNs/trained_on_new_data/dense/N/min_var_2.pth'))\n",
    "#         print('2')\n",
    "    \n",
    "#     network = RnnNetMinVar(5)\n",
    "#     network.load_state_dict(torch.load(fr'./NNs/rnn_minvar.pth'))\n",
    "\n",
    "#     rets = pd.read_csv(RETS_FILE_PATH, index_col=0)\n",
    "#     X = transform_rets_to_NN_input(rets)\n",
    "\n",
    "    weights = network.eval()(X).detach().numpy()[0].tolist()\n",
    "    \n",
    "        \n",
    "    #weights = weights_from_NN(rets, linear_osharpe_networks[0]).tolist()\n",
    "    #print(weights)\n",
    "    # Return the vector as JSON, using the string representation of the date for simplicity\n",
    "    print(date)\n",
    "    print(weights)\n",
    "    return jsonify({'weights': weights})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed150707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:12] \"GET /get_weights?date=2017-12-18 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2017-12-18\n",
      "[0.012147455476224422, 0.9346870183944702, 0.08416198194026947, -0.24602718651294708, 0.21503077447414398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:14] \"GET /get_weights?date=2017-12-26 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2017-12-26\n",
      "[0.20813517272472382, 0.9692394137382507, 0.10887661576271057, -0.32781457901000977, 0.04156355559825897]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:16] \"GET /get_weights?date=2018-01-02 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-01-02\n",
      "[0.18492884933948517, 1.0001306533813477, 0.11657529324293137, -0.3170548379421234, 0.015419925563037395]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:18] \"GET /get_weights?date=2018-01-08 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-01-08\n",
      "[0.2890233099460602, 0.9136945009231567, 0.13299307227134705, -0.3209146559238434, -0.014796145260334015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:21] \"GET /get_weights?date=2018-01-16 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-01-16\n",
      "[0.45167404413223267, 0.7903957366943359, 0.1477908194065094, -0.3442613184452057, -0.04559926688671112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:23] \"GET /get_weights?date=2018-01-22 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-01-22\n",
      "[0.410580039024353, 0.8368309140205383, 0.11412940174341202, -0.3632015883922577, 0.0016612542094662786]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:25] \"GET /get_weights?date=2018-01-29 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-01-29\n",
      "[0.4258077144622803, 0.9388762712478638, 0.08042963594198227, -0.3815535306930542, -0.06356003880500793]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:28] \"GET /get_weights?date=2018-02-05 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-02-05\n",
      "[0.805451512336731, 0.664972186088562, 0.08006636798381805, -0.403037965297699, -0.14745210111141205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:30] \"GET /get_weights?date=2018-02-12 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-02-12\n",
      "[0.5189889073371887, 0.9997592568397522, 0.00984809547662735, -0.4043571352958679, -0.12423906475305557]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:32] \"GET /get_weights?date=2018-02-20 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-02-20\n",
      "[0.6908828616142273, 0.8676329255104065, -0.05842587351799011, -0.40303561091423035, -0.09705427289009094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:34] \"GET /get_weights?date=2018-02-26 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-02-26\n",
      "[0.7503127455711365, 0.8452669978141785, -0.09158321470022202, -0.3819516897201538, -0.12204477936029434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:36] \"GET /get_weights?date=2018-03-05 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-03-05\n",
      "[0.6372559666633606, 0.9800857901573181, -0.09197185933589935, -0.38066932559013367, -0.1447005718946457]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:39] \"GET /get_weights?date=2018-03-12 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-03-12\n",
      "[0.6500133872032166, 0.996530294418335, -0.09656137228012085, -0.3905445635318756, -0.15943767130374908]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:41] \"GET /get_weights?date=2018-03-19 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-03-19\n",
      "[0.627030074596405, 1.0002315044403076, -0.08867502212524414, -0.3864269554615021, -0.15215982496738434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:43] \"GET /get_weights?date=2018-03-26 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-03-26\n",
      "[0.5431472659111023, 1.0000215768814087, 0.004919607657939196, -0.4204140305519104, -0.127674400806427]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:45] \"GET /get_weights?date=2018-04-02 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-04-02\n",
      "[0.5677798986434937, 1.0000380277633667, -0.0224625151604414, -0.40982991456985474, -0.13552555441856384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seidm\\miniconda3\\envs\\ddow\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "127.0.0.1 - - [31/Mar/2024 20:05:47] \"GET /get_weights?date=2018-04-09 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-04-09\n",
      "[0.509718656539917, 1.00002121925354, 0.021848173812031746, -0.4102841019630432, -0.12130393087863922]\n"
     ]
    }
   ],
   "source": [
    "app.run(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1839cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "update the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894efcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
