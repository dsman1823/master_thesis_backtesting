{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c19210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np,pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from deepdowmine.nn import BachelierNetWithShorting, BachelierNet, BachelierNetWithShortingUpd\n",
    "\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b91069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2cov(corr, std):\n",
    "    cov = corr * np.outer(std, std)\n",
    "    return cov  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbbebb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a block-diagnoal covariance matrix and a vector of means\n",
    "# Block represent sector\n",
    "# bSize  number of assets in the sector\n",
    "# bCorr correlation between assets in the sector\n",
    "def formBlockMatrix(nBlocks, bSize, bCorr):\n",
    "    block = np.ones( (bSize, bSize))*bCorr\n",
    "    block[range(bSize), range(bSize)] = 1 #diagonal is 1\n",
    "    corr = block_diag(*([block]*nBlocks))\n",
    "    return corr\n",
    "\n",
    "\n",
    "\n",
    "def formTrueMatrix(nBlocks, bSize, bCorr):\n",
    "    corr0 = formBlockMatrix(nBlocks, bSize, bCorr)\n",
    "    corr0 = pd.DataFrame(corr0)\n",
    "    cols = corr0.columns.tolist()\n",
    "    np.random.shuffle(cols)\n",
    "    corr0 = corr0[cols].loc[cols].copy(deep=True)\n",
    "    std0 = np.random.uniform(.05, .2, corr0.shape[0])\n",
    "    cov0 = corr2cov(corr0, std0)\n",
    "    mu0 = np.random.normal(std0, std0, cov0.shape[0]).reshape(-1,1)\n",
    "    return mu0, cov0\n",
    "\n",
    "def corr2cov(corr, std):\n",
    "    cov = corr * np.outer(std, std)\n",
    "    return cov\n",
    "\n",
    "# Denoising of the empirical covariance matrix\n",
    "# by constant residual eigenvalue method\n",
    "def deNoiseCov(cov0,q,bWidth):\n",
    "    corr0=cov2corr(cov0)\n",
    "    eVal0,eVec0=getPCA(corr0)\n",
    "    eMax0,var0=findMaxEval(np.diag(eVal0),q,bWidth)\n",
    "    nFacts0=eVal0.shape[0]-np.diag(eVal0)[::-1].searchsorted(eMax0)\n",
    "    corr1=denoisedCorr(eVal0,eVec0,nFacts0)\n",
    "    cov1=corr2cov(corr1,np.diag(cov0)**.5)\n",
    "    return cov1\n",
    "\n",
    "\n",
    "# function to obtain empirical from true matrix with and without shrink\n",
    "def simCovMu(mu0,cov0,nObs,shrink=False):\n",
    "    x=np.random.multivariate_normal(mu0.flatten(),cov0,size=nObs)\n",
    "    mu1=x.mean(axis=0).reshape(-1,1)\n",
    "    if shrink:cov1=LedoitWolf().fit(x).covariance_\n",
    "    else:cov1=np.cov(x,rowvar=0)\n",
    "    return mu1,cov1, x\n",
    "\n",
    "# replace in random eigenvalues by constants\n",
    "def denoisedCorr(eVal, eVec, nFacts):\n",
    "    eVal_ = np.diag(eVal).copy()\n",
    "    eVal_[nFacts:] = eVal_[nFacts:].sum()/float(eVal_.shape[0] - nFacts) #all but 0..i values equals (1/N-i)sum(eVal_[i..N]))\n",
    "    eVal_ = np.diag(eVal_) #square matrix with eigenvalues as diagonal: eVal_.I\n",
    "    corr1 = np.dot(eVec, eVal_).dot(eVec.T) #Eigendecomposition of a symmetric matrix: S = QÎ›QT\n",
    "    corr1 = cov2corr(corr1) # Rescaling the correlation matrix to have 1s on the main diagonal\n",
    "    return corr1\n",
    "\n",
    "\n",
    "def getRndCov(nCols, nFacts): #nFacts - contains signal out of nCols\n",
    "    w = np.random.normal(size=(nCols, nFacts))\n",
    "    cov = np.dot(w, w.T) #random cov matrix, however not full rank\n",
    "    cov += np.diag(np.random.uniform(size=nCols)) #full rank cov\n",
    "    return cov\n",
    "\n",
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov/np.outer(std,std)\n",
    "    corr[corr<-1], corr[corr>1] = -1,1 #for numerical errors\n",
    "    return corr\n",
    "    \n",
    "def corr2cov(corr, std):\n",
    "    cov = corr * np.outer(std, std)\n",
    "    return cov     \n",
    "    \n",
    "#snippet 2.4 - fitting the marcenko-pastur pdf - find variance\n",
    "#Fit error\n",
    "def errPDFs(var, eVal, q, bWidth, pts=1000):\n",
    "    var = var[0]\n",
    "    pdf0 = mpPDF(var, q, pts) #theoretical pdf\n",
    "    pdf1 = fitKDE(eVal, bWidth, x=pdf0.index.values) #empirical pdf\n",
    "    sse = np.sum((pdf1-pdf0)**2)\n",
    "    print(\"sse:\"+str(sse))\n",
    "    return sse \n",
    "    \n",
    "# find max random eVal by fitting Marcenko's dist\n",
    "# and return variance\n",
    "def findMaxEval(eVal, q, bWidth):\n",
    "    out = minimize(lambda *x: errPDFs(*x), x0=np.array(0.5), args=(eVal, q, bWidth), bounds=((1E-5, 1-1E-5),))\n",
    "    print(\"found errPDFs\"+str(out['x'][0]))\n",
    "    if out['success']: var = out['x'][0]\n",
    "    else: var=1\n",
    "    eMax = var*(1+(1./q)**.5)**2\n",
    "    return eMax, var\n",
    "\n",
    "\n",
    "\n",
    "def getPCA(matrix):\n",
    "# Get eVal,eVec from a !!!Hermitian matrix (cov matrix is a hermitian matrix)\n",
    "    eVal,eVec=np.linalg.eigh(matrix) \n",
    "    indices=eVal.argsort()[::-1] # arguments for sorting eVal desc\n",
    "    eVal,eVec=eVal[indices],eVec[:,indices]\n",
    "    eVal=np.diagflat(eVal)\n",
    "    return eVal,eVec\n",
    "\n",
    "\n",
    "def fitKDE(obs,bWidth=.25,kernel='gaussian',x=None):\n",
    "    # Fit kernel to a series of obs, and derive the prob of obs\n",
    "    # x is the array of values on which the fit KDE will be evaluated\n",
    "    if len(obs.shape)==1:obs=obs.reshape(-1,1)\n",
    "    kde=KernelDensity(kernel=kernel,bandwidth=bWidth).fit(obs)\n",
    "    if x is None:x=np.unique(obs).reshape(-1,1)\n",
    "    if len(x.shape)==1:x=x.reshape(-1,1)\n",
    "    logProb=kde.score_samples(x) # log(density)\n",
    "    pdf=pd.Series(np.exp(logProb),index=x.flatten())\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def mpPDF(var,q,pts):\n",
    "    # Marcenko-Pastur pdf\n",
    "    # q=T/N (>1)\n",
    "    # pts - amount of points\n",
    "    eMin,eMax=var*(1-(1./q)**.5)**2,var*(1+(1./q)**.5)**2\n",
    "    eVal=np.linspace(eMin,eMax,pts)\n",
    "    pdf=q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5\n",
    "    pdf=pd.Series(pdf,index=eVal)\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def getRndCov(nCols, nFacts): #nFacts - contains signal out of nCols\n",
    "    w = np.random.normal(size=(nCols, nFacts))\n",
    "    cov = np.dot(w, w.T) #random cov matrix, however not full rank\n",
    "    cov += np.diag(np.random.uniform(size=nCols)) #full rank cov\n",
    "    return cov\n",
    "\n",
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov/np.outer(std,std)\n",
    "    corr[corr<-1], corr[corr>1] = -1,1 #for numerical errors\n",
    "    return corr\n",
    "    \n",
    "def corr2cov(corr, std):\n",
    "    cov = corr * np.outer(std, std)\n",
    "    return cov     \n",
    "    \n",
    "#snippet 2.4 - fitting the marcenko-pastur pdf - find variance\n",
    "#Fit error\n",
    "def errPDFs(var, eVal, q, bWidth, pts=1000):\n",
    "    var = var[0]\n",
    "    pdf0 = mpPDF(var, q, pts) #theoretical pdf\n",
    "    pdf1 = fitKDE(eVal, bWidth, x=pdf0.index.values) #empirical pdf\n",
    "    sse = np.sum((pdf1-pdf0)**2)\n",
    "    print(\"sse:\"+str(sse))\n",
    "    return sse \n",
    "    \n",
    "# find max random eVal by fitting Marcenko's dist\n",
    "# and return variance\n",
    "def findMaxEval(eVal, q, bWidth):\n",
    "    out = minimize(lambda *x: errPDFs(*x), x0=np.array(0.5), args=(eVal, q, bWidth), bounds=((1E-5, 1-1E-5),))\n",
    "    print(\"found errPDFs\"+str(out['x'][0]))\n",
    "    if out['success']: var = out['x'][0]\n",
    "    else: var=1\n",
    "    eMax = var*(1+(1./q)**.5)**2\n",
    "    return eMax, var\n",
    "\n",
    "\n",
    "# find min var portfolio\n",
    "def optPort(cov,mu=None):\n",
    "    inv=np.linalg.inv(cov)\n",
    "    ones=np.ones(shape=(inv.shape[0],1))\n",
    "    if mu is None:mu=ones\n",
    "    w=np.dot(inv,mu)\n",
    "    w/=np.dot(ones.T,w)\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def minimize_portfolio_variance(cov_matrix):\n",
    "    \"\"\"\n",
    "    Finds the portfolio weights that minimize the portfolio variance.\n",
    "    \n",
    "    :param cov_matrix: The covariance matrix of asset returns.\n",
    "    :return: Optimal portfolio weights as a numpy array.\n",
    "    \"\"\"\n",
    "    # Number of assets\n",
    "    n = cov_matrix.shape[0]\n",
    "\n",
    "    # Portfolio weights variables\n",
    "    w = cp.Variable(n)\n",
    "\n",
    "    # Portfolio variance\n",
    "    port_variance = cp.quad_form(w, cov_matrix)\n",
    "\n",
    "    # Objective Function: Minimize portfolio variance\n",
    "    objective = cp.Minimize(port_variance)\n",
    "\n",
    "    # Constraints: weights sum to 1, non-negativity\n",
    "    constraints = [cp.sum(w) == 1]\n",
    "\n",
    "    # Problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem.solve()\n",
    "\n",
    "    # Portfolio weights\n",
    "    optimal_weights = w.value\n",
    "    \n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "def transform_returns_to_Xy_tensors(returns, lookback, n_timesteps, horizon, gap):\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for i in range(lookback, n_timesteps - horizon - gap + 1):\n",
    "        X_list.append(returns[i - lookback: i, :])\n",
    "        y_list.append(returns[i + gap: i + gap + horizon, :])\n",
    "\n",
    "    X = np.stack(X_list, axis=0)[:, None, ...]\n",
    "    y = np.stack(y_list, axis=0)[:, None, ...]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def X_to_tensor(X, loockback, i = None):\n",
    "    \n",
    "    \n",
    "    if i:\n",
    "        if i < loockback:\n",
    "            raise ValueError(\"i must not be greater than lookback\")\n",
    "    else: i = -1\n",
    "    # Parameters\n",
    "    i = len(X) if i == -1 else i\n",
    "\n",
    "    # Slicing X and reshaping\n",
    "    X_slice = X[i - lookback: i, :]  # This is (40, 250)\n",
    "    X_tensor = torch.tensor(X_slice).unsqueeze(0).unsqueeze(0)  # Adding two dimensions\n",
    "    return torch.tensor(X_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e256d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lookback, gap, horizon = 40, 0, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ce1c90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Should be run after the code below to obtain X!!!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m n_timesteps, n_assets \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Should be run after the code below to obtain X!!!\n",
    "n_timesteps, n_assets = X.shape\n",
    "# tX, ty = transform_returns_to_Xy_tensors(X, lookback, n_timesteps, horizon, gap)\n",
    "# res = torch.tensor(tX[[-1]], dtype=torch.float32)#(X[indices_train], dtype=torch.float32) #indices_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2da51c",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!! Recheck how deep dow trains the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0407d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tensorX \u001b[38;5;241m=\u001b[39m X_to_tensor(\u001b[43mX\u001b[49m, \u001b[38;5;241m40\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "tensorX = X_to_tensor(X, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3756b12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensorX\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorX' is not defined"
     ]
    }
   ],
   "source": [
    "tensorX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31eea58b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m[[\u001b[38;5;241m999\u001b[39m], \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X[[999], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9254818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensorX\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m39\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorX' is not defined"
     ]
    }
   ],
   "source": [
    "tensorX[0, 0, 39, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401f677f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m[[\u001b[38;5;241m959\u001b[39m, \u001b[38;5;241m960\u001b[39m, \u001b[38;5;241m961\u001b[39m], \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X[[959, 960, 961], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ae3b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensorX\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorX' is not defined"
     ]
    }
   ],
   "source": [
    "tensorX[0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18090aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m value_to_find \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0678\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Since we are dealing with floating-point numbers, we use a small tolerance\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = X[0:1000, 0]\n",
    "value_to_find = 0.0678\n",
    "\n",
    "# Since we are dealing with floating-point numbers, we use a small tolerance\n",
    "tolerance = 1e-4\n",
    "\n",
    "# Finding indices where value matches\n",
    "indices = np.where(np.abs(arr - value_to_find) < tolerance)\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf69293",
   "metadata": {},
   "source": [
    "# !!!! End recheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4644655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395ecfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Roaming\\Python\\Python310\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:235: UserWarning: Your problem has too many parameters for efficient DPP compilation. We suggest setting 'ignore_dpp = True'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "network = network = BachelierNetWithShortingUpd(#BachelierNet(\n",
    "        1,\n",
    "        250,\n",
    "        hidden_size=32,\n",
    "        shrinkage_strategy=\"diagonal\",\n",
    "        p=0.5,\n",
    "    )\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a86930",
   "metadata": {},
   "source": [
    "# Experiment max sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "695b3250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:467.59704005413346\n",
      "sse:467.5970033168651\n",
      "sse:6.3218817600391\n",
      "sse:6.321881601233473\n",
      "sse:6.290716638374266\n",
      "sse:6.290716768970462\n",
      "sse:6.2325479970063355\n",
      "sse:6.2325479777179815\n",
      "sse:6.231437430828756\n",
      "sse:6.231437432697209\n",
      "sse:6.2314267187544425\n",
      "sse:6.231426718777547\n",
      "sse:6.231426717131079\n",
      "sse:6.2314267171310425\n",
      "found errPDFs0.9890425875960898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:464.3881886200861\n",
      "sse:464.3881534605644\n",
      "sse:7.695839030525285\n",
      "sse:7.695838968403435\n",
      "sse:7.691020741439032\n",
      "sse:7.691020788503038\n",
      "sse:7.684947491605444\n",
      "sse:7.684947487424775\n",
      "sse:7.684903765468382\n",
      "sse:7.684903765750695\n",
      "sse:7.684903563605511\n",
      "sse:7.684903563607184\n",
      "sse:7.68490356359925\n",
      "sse:7.684903563599248\n",
      "found errPDFs0.9965624292317469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:463.45186315263106\n",
      "sse:463.4518257002054\n",
      "sse:8.840917081652472\n",
      "sse:8.840916934114135\n",
      "sse:8.815044824271759\n",
      "sse:8.81504494007292\n",
      "sse:8.780155003764389\n",
      "sse:8.780154976993602\n",
      "sse:8.778665579449997\n",
      "sse:8.778665583659873\n",
      "sse:8.778625792787691\n",
      "sse:8.778625792927398\n",
      "sse:8.778625749289034\n",
      "sse:8.778625749288285\n",
      "sse:8.778625749287427\n",
      "sse:8.778625749287425\n",
      "found errPDFs0.9920248372250414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:470.19348070041974\n",
      "sse:470.1934464321243\n",
      "sse:8.743298740898418\n",
      "sse:8.743298566922398\n",
      "sse:8.704077645041014\n",
      "sse:8.704077781286909\n",
      "sse:8.648134725661293\n",
      "sse:8.64813470732602\n",
      "sse:8.647227755173265\n",
      "sse:8.647227756672123\n",
      "sse:8.64722156976433\n",
      "sse:8.647221569778557\n",
      "sse:8.647221569214395\n",
      "sse:8.647221569214388\n",
      "found errPDFs0.9893436627970549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:472.87127395938796\n",
      "sse:472.87123834141755\n",
      "sse:6.0864751826497585\n",
      "sse:6.086475160372996\n",
      "sse:6.085873202879727\n",
      "sse:6.0858732191188345\n",
      "sse:6.085199379842224\n",
      "sse:6.085199379567224\n",
      "sse:6.085199189669968\n",
      "sse:6.085199189673425\n",
      "sse:6.0851991896417985\n",
      "sse:6.085199189641788\n",
      "found errPDFs0.9988507513519889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:457.35125451060287\n",
      "sse:457.351221289664\n",
      "sse:7.09041033471912\n",
      "sse:7.09041020526642\n",
      "sse:7.067445788012952\n",
      "sse:7.067445894973375\n",
      "sse:7.026424102979898\n",
      "sse:7.026424075432329\n",
      "sse:7.024370484528717\n",
      "sse:7.024370489714494\n",
      "sse:7.024288960389965\n",
      "sse:7.024288960635243\n",
      "sse:7.024288779830167\n",
      "sse:7.024288779827933\n",
      "sse:7.024288779814115\n",
      "sse:7.024288779814112\n",
      "found errPDFs0.9903960740099611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:466.05716142222775\n",
      "sse:466.0571227504434\n",
      "sse:6.900802175267851\n",
      "sse:6.900802079572668\n",
      "sse:6.890230904158669\n",
      "sse:6.890230979661567\n",
      "sse:6.87391938576046\n",
      "sse:6.873919378914705\n",
      "sse:6.873798062012765\n",
      "sse:6.873798062515603\n",
      "sse:6.873797397602865\n",
      "sse:6.873797397606335\n",
      "sse:6.8737973975730595\n",
      "sse:6.873797397573044\n",
      "found errPDFs0.9944981169581059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:471.58288895967456\n",
      "sse:471.5828559873971\n",
      "sse:4.564871452749237\n",
      "sse:4.5648713586223355\n",
      "sse:4.553336912533835\n",
      "sse:4.553336980399179\n",
      "sse:4.5412397716921165\n",
      "sse:4.541239768884991\n",
      "sse:4.541219904292731\n",
      "sse:4.541219904378899\n",
      "sse:4.541219885565507\n",
      "sse:4.541219885565619\n",
      "sse:4.541219885565532\n",
      "sse:4.5412198855655355\n",
      "sse:4.541219885565507\n",
      "sse:4.541219885565599\n",
      "found errPDFs0.995030434228278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:470.57804277044033\n",
      "sse:470.578005946292\n",
      "sse:6.83472443482886\n",
      "sse:6.834724356987897\n",
      "sse:6.827464893913015\n",
      "sse:6.827464953604742\n",
      "sse:6.817944753583371\n",
      "sse:6.817944746809631\n",
      "sse:6.817835652371276\n",
      "sse:6.817835652948047\n",
      "sse:6.817834845073589\n",
      "sse:6.817834845078949\n",
      "sse:6.817834845006742\n",
      "sse:6.817834845006728\n",
      "found errPDFs0.9957920677614541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:463.6513128185861\n",
      "sse:463.6512784901105\n",
      "sse:8.505464434749793\n",
      "sse:8.505464285924283\n",
      "sse:8.476295959285139\n",
      "sse:8.476296080473436\n",
      "sse:8.426858310805262\n",
      "sse:8.426858286657856\n",
      "sse:8.42524025901662\n",
      "sse:8.425240262317532\n",
      "sse:8.425208230590119\n",
      "sse:8.42520823067323\n",
      "sse:8.425208210405867\n",
      "sse:8.425208210405563\n",
      "sse:8.425208210405462\n",
      "sse:8.425208210405483\n",
      "found errPDFs0.9897462546118141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:467.84651186082544\n",
      "sse:467.8464759027892\n",
      "sse:7.517281525535143\n",
      "sse:7.51728135473185\n",
      "sse:7.480897420328173\n",
      "sse:7.4808975570802225\n",
      "sse:7.422035863520998\n",
      "sse:7.422035846264418\n",
      "sse:7.4211919495865475\n",
      "sse:7.421191950920755\n",
      "sse:7.42118681476548\n",
      "sse:7.421186814776455\n",
      "sse:7.421186814423994\n",
      "sse:7.421186814423992\n",
      "found errPDFs0.9891199353227182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:476.84579366452147\n",
      "sse:476.845754251078\n",
      "sse:8.228875350205948\n",
      "sse:8.228875269375697\n",
      "sse:8.221363510407393\n",
      "sse:8.221363576354472\n",
      "sse:8.206889375661572\n",
      "sse:8.206889372756509\n",
      "sse:8.206862539572363\n",
      "sse:8.206862539670615\n",
      "sse:8.20686250883542\n",
      "sse:8.20686250883554\n",
      "sse:8.206862508835417\n",
      "sse:8.20686250883543\n",
      "found errPDFs0.9946175434835782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:473.91995343808173\n",
      "sse:473.9199154860844\n",
      "sse:6.652239020485496\n",
      "sse:6.652238950949897\n",
      "sse:6.646403908632262\n",
      "sse:6.646403966688366\n",
      "sse:6.633535896053111\n",
      "sse:6.63353589267202\n",
      "sse:6.63349489674872\n",
      "sse:6.633494896904823\n",
      "sse:6.633494808928246\n",
      "sse:6.633494808928645\n",
      "sse:6.633494808927853\n",
      "sse:6.633494808927856\n",
      "found errPDFs0.994694343255103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:473.5960927716048\n",
      "sse:473.59605384049246\n",
      "sse:9.219847711190084\n",
      "sse:9.219847616269202\n",
      "sse:9.20934936135933\n",
      "sse:9.209349439044898\n",
      "sse:9.18883631145636\n",
      "sse:9.188836307484499\n",
      "sse:9.18878555921368\n",
      "sse:9.188785559375617\n",
      "sse:9.18878547454377\n",
      "sse:9.188785474544114\n",
      "sse:9.188785474543582\n",
      "sse:9.188785474543572\n",
      "found errPDFs0.9935486733065703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:481.1591302905639\n",
      "sse:481.1590952754319\n",
      "sse:7.0156272148328656\n",
      "sse:7.01562720799658\n",
      "sse:7.015568533728622\n",
      "sse:7.015568538916598\n",
      "sse:7.01548922232418\n",
      "sse:7.01548922229206\n",
      "sse:7.01548921928726\n",
      "sse:7.015489219287414\n",
      "found errPDFs0.9995871071700265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE not denoised:0.007128821594753795\n",
      "RMSE denoised:0.002854220696416619\n",
      "RMSE neural:0.009852407308599178\n"
     ]
    }
   ],
   "source": [
    "network.load_state_dict(torch.load('bachelier_with_shorting_250assets_max_sharpe_ratio_loss.pth'))\n",
    "\n",
    "\n",
    "np.random.seed(32)\n",
    "# block is a sector with bSize assets\n",
    "nBlocks, bSize, bCorr = 2, 125, .01 #5, 50, .5\n",
    "np.random.seed(0)\n",
    "mu0, cov0 = formTrueMatrix(nBlocks, bSize, bCorr)\n",
    "\n",
    "nObs, nTrials, bWidth, shrink = 1000, 15, .01, False\n",
    "w1 = pd.DataFrame(columns = range(cov0.shape[0]), index = range(nTrials), dtype=float)\n",
    "w1_d = w1.copy(deep=True)\n",
    "w1_n = w1.copy(deep=True)\n",
    "\n",
    "covs1 = []\n",
    "covs1_d = []\n",
    "covs1_n = []\n",
    "np.random.seed(0)\n",
    "for i in range(nTrials):\n",
    "    mu1, cov1, X = simCovMu(mu0, cov0, nObs, shrink = shrink)\n",
    "    cov1_d = deNoiseCov(cov1, nObs*1./cov1.shape[1], bWidth)\n",
    "    w1.loc[i] = optPort(cov1,mu1).flatten()   #optPort(cov1, mu1).flatten() # add column vector w as row in w1\n",
    "    w1_d.loc[i] = optPort(cov1_d,mu1).flatten() #optPort(cov1_d, mu1).flatten() # np.sum(w1_d, axis=1) is vector of 1's. sum(np.sum(w1_d, axis=0)= nTrials\n",
    "    # so minimum-variance-portfolio is 1./nTrials*(np.sum(w1_d, axis=0)) - but distribution not stationary\n",
    "    tensorX = X_to_tensor(X, lookback)\n",
    "    weights_n = network(tensorX)\n",
    "    w1_n.loc[i] = weights_n.detach().numpy().flatten()#network(tensorX)\n",
    "    \n",
    "    \n",
    "    covs1.append(cov1)\n",
    "    covs1_d.append(cov1_d)\n",
    "    \n",
    "min_var_port = 1./nTrials*(np.sum(w1_d, axis=0)) \n",
    "#code snippet 2.11\n",
    "w0 = optPort(cov0, mu0) # w0 true percentage asset allocation\n",
    "w0 = np.repeat(w0.T, w1.shape[0], axis=0) \n",
    "rmsd = np.mean((w1-w0).values.flatten()**2)**.5     #RMSE not denoised\n",
    "rmsd_d = np.mean((w1_d-w0).values.flatten()**2)**.5 #RMSE denoised\n",
    "rmsd_n = np.mean((w1_n-w0).values.flatten()**2)**.5 #\n",
    "print(\"RMSE not denoised:\"+str( rmsd))\n",
    "print(\"RMSE denoised:\"+str( rmsd_d))\n",
    "print(\"RMSE neural:\"+str( rmsd_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed5a0d",
   "metadata": {},
   "source": [
    "# Experiment min var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c484e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:380.1222153602247\n",
      "sse:380.12218337918733\n",
      "sse:13.857915505690334\n",
      "sse:13.857914507377078\n",
      "sse:12.353271992413202\n",
      "sse:12.353272975057623\n",
      "sse:7.589232982166741\n",
      "sse:7.589233471340651\n",
      "sse:9.419677502786264\n",
      "sse:9.419676466641612\n",
      "sse:6.851995945807821\n",
      "sse:6.851996030615355\n",
      "sse:6.837027178947828\n",
      "sse:6.837027150686332\n",
      "sse:6.835306346660733\n",
      "sse:6.835306347832209\n",
      "sse:6.835303330700496\n",
      "sse:6.835303330715952\n",
      "sse:6.835303330183313\n",
      "sse:6.835303330183308\n",
      "found errPDFs0.8960743862203008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:382.0071250540165\n",
      "sse:382.0070932472376\n",
      "sse:13.93898867040518\n",
      "sse:13.93898789417521\n",
      "sse:13.018952226826595\n",
      "sse:13.018952996053578\n",
      "sse:9.658490621516489\n",
      "sse:9.658491184873949\n",
      "sse:24.769587038551524\n",
      "sse:24.769584662850335\n",
      "sse:8.59291864297828\n",
      "sse:8.59291880018418\n",
      "sse:8.557336084789855\n",
      "sse:8.557335975275592\n",
      "sse:8.53720813395934\n",
      "sse:8.537208147763856\n",
      "sse:8.536836057169548\n",
      "sse:8.536836058392879\n",
      "sse:8.536833152451813\n",
      "sse:8.536833152438225\n",
      "sse:8.536833152087\n",
      "sse:8.536833152087002\n",
      "found errPDFs0.9058024202922926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:385.529565735957\n",
      "sse:385.52953644925134\n",
      "sse:12.659736958338923\n",
      "sse:12.659736130129279\n",
      "sse:11.574657002384665\n",
      "sse:11.574657754060166\n",
      "sse:8.066505461995256\n",
      "sse:8.06650595623314\n",
      "sse:12.715468744616059\n",
      "sse:12.715466727881573\n",
      "sse:7.3025204097716\n",
      "sse:7.302520316976844\n",
      "sse:7.270223534615868\n",
      "sse:7.270223536545941\n",
      "sse:7.2702208361319585\n",
      "sse:7.270220834728823\n",
      "sse:7.270217809901256\n",
      "sse:7.2702178099013555\n",
      "found errPDFs0.9043965488939348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:380.78312419400504\n",
      "sse:380.78309113795314\n",
      "sse:13.6268775178538\n",
      "sse:13.62687645552667\n",
      "sse:12.057138508430729\n",
      "sse:12.05713946201212\n",
      "sse:10.115351186108537\n",
      "sse:10.115349848800996\n",
      "sse:7.700067092594667\n",
      "sse:7.700067647160752\n",
      "sse:10.020869092439167\n",
      "sse:10.020867784912907\n",
      "sse:6.736822619890477\n",
      "sse:6.736822719460601\n",
      "sse:6.7211083037389905\n",
      "sse:6.721108253748792\n",
      "sse:6.716425652977529\n",
      "sse:6.716425655293085\n",
      "sse:6.716415274011314\n",
      "sse:6.716415274062044\n",
      "sse:6.716415269059676\n",
      "sse:6.716415269059627\n",
      "found errPDFs0.8964775733541941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:395.23417970017385\n",
      "sse:395.234145317105\n",
      "sse:13.929203425971517\n",
      "sse:13.92920232218465\n",
      "sse:12.249875047124789\n",
      "sse:12.249876096414324\n",
      "sse:7.671297516999221\n",
      "sse:7.671297742387631\n",
      "sse:7.668968153677173\n",
      "sse:7.6689681469460185\n",
      "sse:7.668781245281645\n",
      "sse:7.668781243963115\n",
      "sse:7.668762475393416\n",
      "sse:7.66876247395594\n",
      "sse:7.668556195121475\n",
      "sse:7.668556187856083\n",
      "sse:7.659098292642564\n",
      "sse:7.659098207386433\n",
      "sse:7.5765580744862415\n",
      "sse:7.576558096028457\n",
      "sse:7.578060495907016\n",
      "sse:7.578060457295652\n",
      "sse:7.575839683981737\n",
      "sse:7.575839684097312\n",
      "sse:7.577210369675302\n",
      "sse:7.577210339385504\n",
      "sse:7.575839663722664\n",
      "sse:7.575839663723312\n",
      "sse:7.5758396637223555\n",
      "sse:7.575839663722354\n",
      "found errPDFs0.9141740861012978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:378.97436179527426\n",
      "sse:378.9743334987356\n",
      "sse:14.251512805494308\n",
      "sse:14.251512029190913\n",
      "sse:13.265124524465822\n",
      "sse:13.26512522712305\n",
      "sse:10.229549055933834\n",
      "sse:10.229549468576186\n",
      "sse:11.004110849021243\n",
      "sse:11.004109906863723\n",
      "sse:9.369890198092829\n",
      "sse:9.369890417547238\n",
      "sse:10.670316475828475\n",
      "sse:10.67031576279727\n",
      "sse:9.314288287897774\n",
      "sse:9.314288296429062\n",
      "sse:9.314140443664176\n",
      "sse:9.31414044750014\n",
      "sse:9.314102746453228\n",
      "sse:9.314102746477436\n",
      "sse:9.314102744959945\n",
      "sse:9.314102744959987\n",
      "found errPDFs0.8933681433847541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:381.70990462367945\n",
      "sse:381.7098744543272\n",
      "sse:13.418521019715199\n",
      "sse:13.418519965410498\n",
      "sse:11.650011649701998\n",
      "sse:11.650012685971916\n",
      "sse:6.32494951553624\n",
      "sse:6.324949865142559\n",
      "sse:6.459198174665559\n",
      "sse:6.459198080158031\n",
      "sse:6.043506109624819\n",
      "sse:6.043506168172841\n",
      "sse:6.03708704680177\n",
      "sse:6.037087035164305\n",
      "sse:6.036836857735035\n",
      "sse:6.0368368581114265\n",
      "sse:6.036836593589673\n",
      "sse:6.03683659359211\n",
      "sse:6.036836593579814\n",
      "sse:6.036836593579815\n",
      "found errPDFs0.8999675251709803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:391.15726867177705\n",
      "sse:391.15723650052297\n",
      "sse:14.322131565606957\n",
      "sse:14.322130567088617\n",
      "sse:12.786586182441477\n",
      "sse:12.786587220085224\n",
      "sse:7.565046236986904\n",
      "sse:7.5650466955989675\n",
      "sse:9.60641668099639\n",
      "sse:9.60641547434672\n",
      "sse:7.118339002936832\n",
      "sse:7.118338972823616\n",
      "sse:7.116871533944236\n",
      "sse:7.116871539546658\n",
      "sse:7.116817735177946\n",
      "sse:7.11681773525416\n",
      "sse:7.116817725291849\n",
      "sse:7.11681772529166\n",
      "found errPDFs0.9061587281720211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:394.34981348111745\n",
      "sse:394.3497803338946\n",
      "sse:14.505572578658725\n",
      "sse:14.50557153825783\n",
      "sse:12.984067876803945\n",
      "sse:12.98406883128535\n",
      "sse:8.804819806897779\n",
      "sse:8.804820122607957\n",
      "sse:8.718028673461724\n",
      "sse:8.718028332475866\n",
      "sse:8.589393353517496\n",
      "sse:8.589393305010635\n",
      "sse:8.581043887741878\n",
      "sse:8.58104386675845\n",
      "sse:8.581164594131323\n",
      "sse:8.581164618181297\n",
      "sse:8.58018694314459\n",
      "sse:8.580186942932537\n",
      "sse:8.5801868635843\n",
      "sse:8.580186863599081\n",
      "sse:8.580186863205036\n",
      "sse:8.580186863205007\n",
      "found errPDFs0.9108956841011453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:379.6741035994103\n",
      "sse:379.6740742659978\n",
      "sse:13.17357261003458\n",
      "sse:13.173571777744911\n",
      "sse:12.039947578608178\n",
      "sse:12.039948390115224\n",
      "sse:8.127393945505753\n",
      "sse:8.127394466385821\n",
      "sse:14.291150374914587\n",
      "sse:14.29114917566973\n",
      "sse:7.269023095584642\n",
      "sse:7.269023307214807\n",
      "sse:7.197670124749594\n",
      "sse:7.197669968905499\n",
      "sse:7.158787811166351\n",
      "sse:7.158787838478938\n",
      "sse:7.1572795862975065\n",
      "sse:7.157279589699984\n",
      "sse:7.157256439881408\n",
      "sse:7.15725643980491\n",
      "sse:7.157256428180649\n",
      "sse:7.157256428180853\n",
      "found errPDFs0.8984235641712158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:393.8232656156468\n",
      "sse:393.82323238102197\n",
      "sse:13.685461178691003\n",
      "sse:13.685460250004756\n",
      "sse:12.470598394717587\n",
      "sse:12.470599253728523\n",
      "sse:8.520412258699771\n",
      "sse:8.520412805370535\n",
      "sse:13.91507795839728\n",
      "sse:13.915076738459932\n",
      "sse:7.739333406868312\n",
      "sse:7.7393336620425215\n",
      "sse:7.623160248328409\n",
      "sse:7.623160113304772\n",
      "sse:7.58933795424935\n",
      "sse:7.589337968286214\n",
      "sse:7.5889432268879355\n",
      "sse:7.58894322751819\n",
      "sse:7.58894243502776\n",
      "sse:7.588942435024531\n",
      "sse:7.5889424350053405\n",
      "sse:7.588942435005343\n",
      "found errPDFs0.9018421622953805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:393.67997005745696\n",
      "sse:393.67993410461844\n",
      "sse:16.211253509064683\n",
      "sse:16.211252414971185\n",
      "sse:14.628060721087326\n",
      "sse:14.628061766358375\n",
      "sse:9.814878718133585\n",
      "sse:9.814879188930803\n",
      "sse:10.729587588034352\n",
      "sse:10.729586650219268\n",
      "sse:9.221535689806954\n",
      "sse:9.221535742197375\n",
      "sse:9.215922137653163\n",
      "sse:9.21592212619017\n",
      "sse:9.215648934363502\n",
      "sse:9.215648934581912\n",
      "sse:9.215648834707252\n",
      "sse:9.21564883470814\n",
      "sse:9.215648834706043\n",
      "sse:9.215648834706037\n",
      "found errPDFs0.9022784175983923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:394.03161890746094\n",
      "sse:394.03158340265526\n",
      "sse:13.7693245386967\n",
      "sse:13.769323470639748\n",
      "sse:12.278403593125754\n",
      "sse:12.278404563448102\n",
      "sse:8.21689255428614\n",
      "sse:8.216892906492546\n",
      "sse:8.166461431903844\n",
      "sse:8.16646101325906\n",
      "sse:7.860545241940921\n",
      "sse:7.8605453101370175\n",
      "sse:7.849645167071673\n",
      "sse:7.84964515312348\n",
      "sse:7.849194911398823\n",
      "sse:7.849194911857554\n",
      "sse:7.84919441970595\n",
      "sse:7.849194419708963\n",
      "sse:7.849194419686604\n",
      "sse:7.84919441968658\n",
      "found errPDFs0.9072771915382849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:389.57761681058867\n",
      "sse:389.57758374122204\n",
      "sse:14.692474093597799\n",
      "sse:14.69247304713242\n",
      "sse:13.130981884621903\n",
      "sse:13.13098286961722\n",
      "sse:8.691625344894705\n",
      "sse:8.691625678747009\n",
      "sse:8.903379956445432\n",
      "sse:8.903379586888988\n",
      "sse:8.409337375349631\n",
      "sse:8.409337431902758\n",
      "sse:8.402518941579602\n",
      "sse:8.40251893191239\n",
      "sse:8.402322648626702\n",
      "sse:8.402322648894202\n",
      "sse:8.402322497359673\n",
      "sse:8.40232249736096\n",
      "sse:8.402322497356849\n",
      "sse:8.402322497356849\n",
      "found errPDFs0.9067958865436845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:400.01695893888945\n",
      "sse:400.0169268536969\n",
      "sse:12.76692892801203\n",
      "sse:12.766927961077332\n",
      "sse:11.402710924696521\n",
      "sse:11.402711820747149\n",
      "sse:7.620504748590658\n",
      "sse:7.620505021174804\n",
      "sse:7.767450449901143\n",
      "sse:7.76745014760267\n",
      "sse:7.439559391454831\n",
      "sse:7.439559437724395\n",
      "sse:7.435140820844256\n",
      "sse:7.435140813176236\n",
      "sse:7.435021382986899\n",
      "sse:7.435021383196855\n",
      "sse:7.435021292919086\n",
      "sse:7.435021292920042\n",
      "sse:7.435021292917648\n",
      "sse:7.4350212929176624\n",
      "found errPDFs0.9138721502983695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE not denoised:0.005165352609117076\n",
      "RMSE denoised:0.0022113306935519867\n",
      "RMSE neural:0.010870854931073336\n"
     ]
    }
   ],
   "source": [
    "network.load_state_dict(torch.load('bachelier_with_shorting_250assets_min_var_loss.pth'))\n",
    "\n",
    "\n",
    "np.random.seed(32)\n",
    "# block is a sector with bSize assets\n",
    "nBlocks, bSize, bCorr = 2, 125, .1 # 5, 50, .5\n",
    "np.random.seed(0)\n",
    "mu0, cov0 = formTrueMatrix(nBlocks, bSize, bCorr)\n",
    "\n",
    "nObs, nTrials, bWidth, shrink, minVarPortf = 1000, 15, .01, False, True\n",
    "w1 = pd.DataFrame(columns = range(cov0.shape[0]), index = range(nTrials), dtype=float)\n",
    "w1_d = w1.copy(deep=True)\n",
    "w1_n = w1.copy(deep=True)\n",
    "\n",
    "covs1 = []\n",
    "covs1_d = []\n",
    "covs1_n = []\n",
    "np.random.seed(0)\n",
    "for i in range(nTrials):\n",
    "    mu1, cov1, X = simCovMu(mu0, cov0, nObs, shrink = shrink)\n",
    "    if minVarPortf: mu1 = None\n",
    "    cov1_d = deNoiseCov(cov1, nObs*1./cov1.shape[1], bWidth)\n",
    "    w1.loc[i] = minimize_portfolio_variance(cov1).flatten()   #optPort(cov1, mu1).flatten() # add column vector w as row in w1\n",
    "    w1_d.loc[i] = minimize_portfolio_variance(cov1_d).flatten() #optPort(cov1_d, mu1).flatten() # np.sum(w1_d, axis=1) is vector of 1's. sum(np.sum(w1_d, axis=0)= nTrials\n",
    "    # so minimum-variance-portfolio is 1./nTrials*(np.sum(w1_d, axis=0)) - but distribution not stationary\n",
    "    tensorX = X_to_tensor(X, lookback)\n",
    "    weights_n = network(tensorX)\n",
    "    w1_n.loc[i] = weights_n.detach().numpy().flatten()#network(tensorX)\n",
    "    \n",
    "    \n",
    "    covs1.append(cov1)\n",
    "    covs1_d.append(cov1_d)\n",
    "    \n",
    "min_var_port = 1./nTrials*(np.sum(w1_d, axis=0)) \n",
    "#code snippet 2.11\n",
    "w0 = optPort(cov0, None if minVarPortf else mu0) # w0 true percentage asset allocation\n",
    "w0 = np.repeat(w0.T, w1.shape[0], axis=0) \n",
    "rmsd = np.mean((w1-w0).values.flatten()**2)**.5     #RMSE not denoised\n",
    "rmsd_d = np.mean((w1_d-w0).values.flatten()**2)**.5 #RMSE denoised\n",
    "rmsd_n = np.mean((w1_n-w0).values.flatten()**2)**.5 #\n",
    "print(\"RMSE not denoised:\"+str( rmsd))\n",
    "print(\"RMSE denoised:\"+str( rmsd_d))\n",
    "print(\"RMSE neural:\"+str( rmsd_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b6bc3",
   "metadata": {},
   "source": [
    "# Check perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a1c3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = nObs / (nBlocks * bSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83511658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:380.1222153602247\n",
      "sse:380.12218337918733\n",
      "sse:13.857915505690334\n",
      "sse:13.857914507377078\n",
      "sse:12.353271992413202\n",
      "sse:12.353272975057623\n",
      "sse:7.589232982166741\n",
      "sse:7.589233471340651\n",
      "sse:9.419677502786264\n",
      "sse:9.419676466641612\n",
      "sse:6.851995945807821\n",
      "sse:6.851996030615355\n",
      "sse:6.837027178947828\n",
      "sse:6.837027150686332\n",
      "sse:6.835306346660733\n",
      "sse:6.835306347832209\n",
      "sse:6.835303330700496\n",
      "sse:6.835303330715952\n",
      "sse:6.835303330183313\n",
      "sse:6.835303330183308\n",
      "found errPDFs0.8960743862203008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8960743862203008, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr11 = cov2corr(covs1[0])\n",
    "eVal11, eVec11 = getPCA(corr11)\n",
    "eMax11, var11 = findMaxEval(np.diag(eVal11), q, bWidth=.01)\n",
    "nFacts11 = eVal11.shape[0]-np.diag(eVal11)[::-1].searchsorted(eMax11)\n",
    "\n",
    "\n",
    "var11, nFacts11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88d17af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:13689.54796288689\n",
      "sse:13689.54763293188\n",
      "sse:6479.035499294034\n",
      "sse:6479.035564731392\n",
      "found errPDFs0.99999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99999, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr11_d = cov2corr(covs1_d[5])\n",
    "eVal11_d, eVec11_d = getPCA(corr11_d)\n",
    "eMax11_d, var11_d = findMaxEval(np.diag(eVal11_d), q, bWidth=.01)\n",
    "nFacts11_d = eVal11_d.shape[0]-np.diag(eVal11_d)[::-1].searchsorted(eMax11_d)\n",
    "\n",
    "\n",
    "var11_d, nFacts11_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891e7f6",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "048f99f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 250)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_subarrays = 10\n",
    "subarray_size = len(X) // num_subarrays\n",
    "subarrays = np.array([X[i * subarray_size:(i + 1) * subarray_size] for i in range(num_subarrays)])\n",
    " \n",
    "\n",
    "subarrays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d63a4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    # This function will return a hook function that stores the output in a dictionary\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "591efdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_to_allocation_layer = []\n",
    "\n",
    "# for i in range(lookback, 1000):\n",
    "#     # Attach the hook to the covariance_layer, which precedes the channel_collapse_layer\n",
    "#     activations = {}\n",
    "#     hook = network.portfolio_opt_layer.register_forward_hook(get_activation('portfolio_opt_layer'))\n",
    "\n",
    "#     # Now run your data through the network. This will store the output of the covariance_layer in activations\n",
    "#     test_X = X_to_tensor(X, lookback, i)\n",
    "   \n",
    "#     network(test_X)\n",
    "\n",
    "#     # The output you're interested in is now stored in activations['covariance_layer_output']\n",
    "#     input_to_allocation_layer = activations['portfolio_opt_layer']\n",
    "#     inputs_to_allocation_layer.append(input_to_allocation_layer)\n",
    "    \n",
    "#     # Don't forget to remove the hook when you're done to prevent memory leaks\n",
    "#     hook.remove()\n",
    "    \n",
    "    \n",
    "# inputs_to_allocation_layer = np.array(inputs_to_allocation_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddb6589e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reshaped_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs_to_allocation_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;241m960\u001b[39m, \u001b[38;5;241m250\u001b[39m)\n\u001b[0;32m      2\u001b[0m inputs_to_allocation_layer[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], reshaped_inputs[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "reshaped_inputs = inputs_to_allocation_layer.reshape(960, 250)\n",
    "inputs_to_allocation_layer[0, 0, 0], reshaped_inputs[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbe1107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = reshaped_inputs.shape[0]/reshaped_inputs.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49373e7b",
   "metadata": {},
   "source": [
    "## Getting cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba0aa77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r0913246\\AppData\\Local\\Temp\\ipykernel_4108\\2520597956.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(X_tensor, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "test_X = X_to_tensor(X, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "040445b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 40, 250])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10f833fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_n = network.get_covmat(test_X)[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "928c11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_n = np.random.normal(size=(10000, 250))\n",
    "cov_n = np.cov(cov_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2efcefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2fbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr11_n = cov2corr(cov_n)\n",
    "eVal11_n, eVec11_n = getPCA(corr11_n)\n",
    "eMax11_n, var11_n = findMaxEval(np.diag(eVal11_n), 100, bWidth=.01)\n",
    "nFacts11_n = eVal11.shape[0]-np.diag(eVal11_n)[::-1].searchsorted(eMax11)\n",
    "nFacts11_n, var11_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0d087e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 0.99999)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d0c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
